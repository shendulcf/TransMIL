{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Proiects\\\\Github\\\\Transmil'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n",
      "---->Log dir: logs/Camelyon/nlst/fold4\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:37: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "train\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | TransMIL         | 2.7 M \n",
      "1 | loss          | CrossEntropyLoss | 0     \n",
      "2 | AUROC         | AUROC            | 0     \n",
      "3 | valid_metrics | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n",
      "10.689    Total estimated model params size (MB)\n",
      "Epoch 0:   0%|                      | 1/789 [00:24<5:19:46, 24.35s/it, loss=nan]/home/sci/PycharmProjects/chaofan/projects/TransMIL/MyOptimizer/radam.py:50: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "Epoch 0:  89%|█████████████████▊  | 702/789 [28:42<03:33,  2.45s/it, loss=0.661]class 0: acc 0.8687782805429864, correct 384/442\n",
      "class 1: acc 0.17692307692307693, correct 46/260\n",
      "Epoch 0:  89%|█████████████████▊  | 703/789 [28:42<03:30,  2.45s/it, loss=0.661]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|█████████████████▊  | 703/789 [29:00<03:32,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  89%|█████████████████▊  | 704/789 [29:10<03:31,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  89%|█████████████████▊  | 705/789 [29:12<03:28,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  89%|█████████████████▉  | 706/789 [29:12<03:26,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  90%|█████████████████▉  | 707/789 [29:12<03:23,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  90%|█████████████████▉  | 708/789 [29:12<03:20,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  90%|█████████████████▉  | 709/789 [29:13<03:17,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  90%|█████████████████▉  | 710/789 [29:20<03:15,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  90%|██████████████████  | 711/789 [29:30<03:14,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  90%|██████████████████  | 713/789 [29:30<03:08,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  91%|██████████████████  | 715/789 [29:43<03:04,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  91%|██████████████████▏ | 718/789 [30:00<02:58,  2.51s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  91%|██████████████████▏ | 719/789 [30:01<02:55,  2.50s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  91%|██████████████████▎ | 721/789 [30:01<02:49,  2.50s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▎ | 723/789 [30:12<02:45,  2.51s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▎ | 724/789 [30:12<02:42,  2.50s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▍ | 725/789 [30:12<02:40,  2.50s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▍ | 726/789 [30:13<02:37,  2.50s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▍ | 727/789 [30:14<02:34,  2.50s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▍ | 728/789 [30:14<02:32,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▍ | 729/789 [30:14<02:29,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  93%|██████████████████▌ | 730/789 [30:14<02:26,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  93%|██████████████████▌ | 732/789 [30:14<02:21,  2.48s/it, loss=0.661]\u001b[A\n",
      "Validating:  34%|██████████▋                    | 30/87 [01:32<00:24,  2.36it/s]\u001b[A\n",
      "Epoch 0:  93%|██████████████████▌ | 734/789 [30:15<02:16,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  93%|██████████████████▋ | 736/789 [30:16<02:10,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  94%|██████████████████▋ | 738/789 [30:30<02:06,  2.48s/it, loss=0.661]\u001b[A\n",
      "Validating:  40%|████████████▍                  | 35/87 [01:47<00:15,  3.36it/s]\u001b[A\n",
      "Epoch 0:  94%|██████████████████▋ | 739/789 [30:39<02:04,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  94%|██████████████████▊ | 740/789 [30:40<02:01,  2.49s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  94%|██████████████████▊ | 743/789 [30:40<01:53,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  95%|██████████████████▉ | 746/789 [30:40<01:46,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  95%|██████████████████▉ | 749/789 [30:54<01:39,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  95%|███████████████████ | 751/789 [30:55<01:33,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  95%|███████████████████ | 753/789 [30:57<01:28,  2.47s/it, loss=0.661]\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:15<00:45,  1.27s/it]\u001b[A\n",
      "Epoch 0:  96%|███████████████████▏| 755/789 [31:02<01:23,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  96%|███████████████████▏| 757/789 [31:03<01:18,  2.46s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  96%|███████████████████▏| 759/789 [31:20<01:14,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  96%|███████████████████▎| 760/789 [31:26<01:11,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  97%|███████████████████▎| 762/789 [31:26<01:06,  2.48s/it, loss=0.661]\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:44<01:08,  2.55s/it]\u001b[A\n",
      "Epoch 0:  97%|███████████████████▎| 764/789 [31:26<01:01,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  97%|███████████████████▍| 767/789 [31:40<00:54,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  97%|███████████████████▍| 768/789 [31:47<00:52,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  98%|███████████████████▌| 770/789 [31:50<00:47,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  98%|███████████████████▌| 772/789 [31:51<00:42,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  98%|███████████████████▌| 774/789 [31:51<00:37,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  98%|███████████████████▋| 777/789 [32:10<00:29,  2.48s/it, loss=0.661]\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:27<00:13,  1.00s/it]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▋| 778/789 [32:10<00:27,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▋| 779/789 [32:13<00:24,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▊| 780/789 [32:14<00:22,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▊| 781/789 [32:14<00:19,  2.48s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▊| 782/789 [32:14<00:17,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▊| 783/789 [32:14<00:14,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▊| 784/789 [32:14<00:12,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▉| 785/789 [32:15<00:09,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0: 100%|███████████████████▉| 786/789 [32:17<00:07,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0: 100%|███████████████████▉| 787/789 [32:23<00:04,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0: 100%|███████████████████▉| 788/789 [32:23<00:02,  2.47s/it, loss=0.661]\u001b[A\n",
      "Epoch 0: 100%|████████████████████| 789/789 [32:23<00:00,  2.46s/it, loss=0.661]\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:41<00:00,  1.05s/it]\u001b[A/home/sci/PycharmProjects/chaofan/projects/TransMIL/utils/utils.py:67: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x_softmax = [F.softmax(x[i]) for i in range(len(x))]\n",
      "class 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.03125, correct 1/32\n",
      "Epoch 0: 100%|█| 789/789 [32:24<00:00,  2.46s/it, loss=0.661, val_loss=0.640, au\n",
      "                                                                                \u001b[AEpoch 0, global step 350: val_loss reached 0.63956 (best 0.63956), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold4/epoch=00-val_loss=0.6396.ckpt\" as top 1\n",
      "Epoch 1:  89%|▉| 702/789 [28:52<03:34,  2.47s/it, loss=0.663, val_loss=0.640, auclass 0: acc 0.8800904977375565, correct 389/442\n",
      "class 1: acc 0.16153846153846155, correct 42/260\n",
      "Epoch 1:  89%|▉| 703/789 [28:52<03:31,  2.46s/it, loss=0.663, val_loss=0.640, au\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|▉| 703/789 [29:05<03:33,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  89%|▉| 704/789 [29:21<03:32,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  89%|▉| 705/789 [29:23<03:30,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  89%|▉| 706/789 [29:23<03:27,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  90%|▉| 707/789 [29:23<03:24,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  90%|▉| 708/789 [29:23<03:21,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  90%|▉| 709/789 [29:23<03:19,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  90%|▉| 710/789 [29:31<03:17,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  90%|▉| 711/789 [29:39<03:15,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  90%|▉| 712/789 [29:39<03:12,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  91%|▉| 715/789 [29:54<03:05,  2.51s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  91%|▉| 718/789 [30:05<02:58,  2.52s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  91%|▉| 719/789 [30:10<02:56,  2.52s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  91%|▉| 721/789 [30:10<02:50,  2.51s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  92%|▉| 723/789 [30:22<02:46,  2.52s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  92%|▉| 724/789 [30:22<02:43,  2.52s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  92%|▉| 725/789 [30:22<02:40,  2.51s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  92%|▉| 726/789 [30:22<02:38,  2.51s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  92%|▉| 727/789 [30:23<02:35,  2.51s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  92%|▉| 728/789 [30:23<02:32,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  92%|▉| 729/789 [30:23<02:30,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  93%|▉| 730/789 [30:23<02:27,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  93%|▉| 732/789 [30:23<02:22,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  93%|▉| 734/789 [30:24<02:16,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  93%|▉| 736/789 [30:25<02:11,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  94%|▉| 738/789 [30:35<02:06,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Validating:  40%|████████████▍                  | 35/87 [01:43<00:16,  3.18it/s]\u001b[A\n",
      "Epoch 1:  94%|▉| 739/789 [30:51<02:05,  2.51s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  94%|▉| 740/789 [30:51<02:02,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  94%|▉| 743/789 [30:52<01:54,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  95%|▉| 746/789 [31:05<01:47,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Validating:  49%|███████████████▎               | 43/87 [02:13<01:06,  1.52s/it]\u001b[A\n",
      "Epoch 1:  95%|▉| 747/789 [31:06<01:44,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  95%|▉| 750/789 [31:06<01:37,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  95%|▉| 753/789 [31:08<01:29,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:15<00:43,  1.21s/it]\u001b[A\n",
      "Epoch 1:  96%|▉| 756/789 [31:14<01:21,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:22<00:46,  1.42s/it]\u001b[A\n",
      "Epoch 1:  96%|▉| 759/789 [31:35<01:14,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  96%|▉| 760/789 [31:37<01:12,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  97%|▉| 762/789 [31:37<01:07,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:45<01:07,  2.49s/it]\u001b[A\n",
      "Epoch 1:  97%|▉| 764/789 [31:37<01:02,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  97%|▉| 767/789 [31:55<00:54,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  97%|▉| 768/789 [31:59<00:52,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  98%|▉| 770/789 [32:00<00:47,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  98%|▉| 772/789 [32:01<00:42,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  98%|▉| 774/789 [32:01<00:37,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  98%|▉| 777/789 [32:15<00:29,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:23<00:12,  1.06it/s]\u001b[A\n",
      "Epoch 1:  99%|▉| 778/789 [32:21<00:27,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  99%|▉| 780/789 [32:26<00:22,  2.50s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  99%|▉| 781/789 [32:26<00:19,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  99%|▉| 782/789 [32:26<00:17,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  99%|▉| 783/789 [32:26<00:14,  2.49s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  99%|▉| 784/789 [32:27<00:12,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1:  99%|▉| 785/789 [32:27<00:09,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1: 100%|▉| 786/789 [32:27<00:07,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1: 100%|▉| 787/789 [32:34<00:04,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1: 100%|▉| 788/789 [32:34<00:02,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Epoch 1: 100%|█| 789/789 [32:34<00:00,  2.48s/it, loss=0.663, val_loss=0.640, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:42<00:00,  1.05s/it]\u001b[Aclass 0: acc 0.23636363636363636, correct 13/55\n",
      "class 1: acc 0.875, correct 28/32\n",
      "Epoch 1: 100%|█| 789/789 [32:35<00:00,  2.48s/it, loss=0.663, val_loss=0.743, au\n",
      "                                                                                \u001b[AEpoch 1, step 701: val_loss was not in top 1\n",
      "Epoch 2:  89%|▉| 702/789 [28:48<03:34,  2.46s/it, loss=0.654, val_loss=0.743, auclass 0: acc 0.8755656108597285, correct 387/442\n",
      "class 1: acc 0.20384615384615384, correct 53/260\n",
      "Epoch 2:  89%|▉| 703/789 [28:48<03:31,  2.46s/it, loss=0.654, val_loss=0.743, au\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  89%|▉| 703/789 [29:00<03:32,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  89%|▉| 704/789 [29:18<03:32,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  89%|▉| 705/789 [29:20<03:29,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  89%|▉| 706/789 [29:20<03:27,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  90%|▉| 707/789 [29:20<03:24,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  90%|▉| 708/789 [29:21<03:21,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  90%|▉| 709/789 [29:21<03:18,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  90%|▉| 710/789 [29:28<03:16,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  90%|▉| 711/789 [29:36<03:14,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  90%|▉| 712/789 [29:36<03:12,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  91%|▉| 715/789 [29:51<03:05,  2.51s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  91%|▉| 717/789 [29:51<02:59,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  91%|▉| 719/789 [30:06<02:55,  2.51s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  91%|▉| 721/789 [30:07<02:50,  2.51s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  92%|▉| 723/789 [30:18<02:46,  2.52s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  92%|▉| 724/789 [30:18<02:43,  2.51s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  92%|▉| 725/789 [30:19<02:40,  2.51s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  92%|▉| 726/789 [30:19<02:37,  2.51s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  92%|▉| 727/789 [30:19<02:35,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  92%|▉| 728/789 [30:20<02:32,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  92%|▉| 729/789 [30:20<02:29,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  93%|▉| 730/789 [30:20<02:27,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  93%|▉| 732/789 [30:20<02:21,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating:  34%|██████████▋                    | 30/87 [01:32<00:23,  2.41it/s]\u001b[A\n",
      "Epoch 2:  93%|▉| 734/789 [30:21<02:16,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  93%|▉| 736/789 [30:22<02:11,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  94%|▉| 738/789 [30:40<02:07,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating:  40%|████████████▍                  | 35/87 [01:51<00:13,  3.91it/s]\u001b[A\n",
      "Epoch 2:  94%|▉| 739/789 [30:45<02:04,  2.50s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  94%|▉| 740/789 [30:46<02:02,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  94%|▉| 742/789 [30:46<01:56,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  94%|▉| 744/789 [30:46<01:51,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  95%|▉| 746/789 [31:00<01:47,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating:  49%|███████████████▎               | 43/87 [02:11<00:47,  1.08s/it]\u001b[A\n",
      "Epoch 2:  95%|▉| 747/789 [31:00<01:44,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  95%|▉| 750/789 [31:01<01:36,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  95%|▉| 753/789 [31:02<01:29,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:13<00:42,  1.18s/it]\u001b[A\n",
      "Epoch 2:  96%|▉| 756/789 [31:08<01:21,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:19<00:45,  1.37s/it]\u001b[A\n",
      "Epoch 2:  96%|▉| 759/789 [31:30<01:14,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  96%|▉| 760/789 [31:31<01:12,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  97%|▉| 762/789 [31:31<01:07,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:42<01:07,  2.50s/it]\u001b[A\n",
      "Epoch 2:  97%|▉| 764/789 [31:31<01:01,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  97%|▉| 767/789 [31:50<00:54,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  97%|▉| 768/789 [31:52<00:52,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  98%|▉| 770/789 [31:54<00:47,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  98%|▉| 772/789 [31:54<00:42,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  98%|▉| 774/789 [31:54<00:37,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  98%|▉| 777/789 [32:10<00:29,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:21<00:11,  1.09it/s]\u001b[A\n",
      "Epoch 2:  99%|▉| 778/789 [32:14<00:27,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  99%|▉| 779/789 [32:18<00:24,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  99%|▉| 780/789 [32:18<00:22,  2.49s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  99%|▉| 781/789 [32:18<00:19,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  99%|▉| 782/789 [32:18<00:17,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  99%|▉| 783/789 [32:19<00:14,  2.48s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  99%|▉| 784/789 [32:19<00:12,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2:  99%|▉| 785/789 [32:19<00:09,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2: 100%|▉| 786/789 [32:20<00:07,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2: 100%|▉| 787/789 [32:27<00:04,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2: 100%|▉| 788/789 [32:27<00:02,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Epoch 2: 100%|█| 789/789 [32:27<00:00,  2.47s/it, loss=0.654, val_loss=0.743, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:38<00:00,  1.04s/it]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 2: 100%|█| 789/789 [32:27<00:00,  2.47s/it, loss=0.654, val_loss=0.651, au\n",
      "                                                                                \u001b[AEpoch 2, step 1052: val_loss was not in top 1\n",
      "Epoch 3:  89%|▉| 702/789 [28:44<03:33,  2.46s/it, loss=0.488, val_loss=0.651, auclass 0: acc 0.8393665158371041, correct 371/442\n",
      "class 1: acc 0.3076923076923077, correct 80/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  89%|▉| 703/789 [29:02<03:33,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  89%|▉| 704/789 [29:13<03:31,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  89%|▉| 705/789 [29:15<03:29,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  89%|▉| 706/789 [29:15<03:26,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  90%|▉| 707/789 [29:15<03:23,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  90%|▉| 708/789 [29:16<03:20,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  90%|▉| 709/789 [29:16<03:18,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  90%|▉| 710/789 [29:22<03:16,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  90%|▉| 711/789 [29:31<03:14,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  90%|▉| 714/789 [29:42<03:07,  2.50s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  91%|▉| 715/789 [29:45<03:04,  2.50s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  91%|▉| 717/789 [29:45<02:59,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  91%|▉| 719/789 [30:02<02:55,  2.51s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  92%|▉| 722/789 [30:12<02:48,  2.51s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  22%|██████▊                        | 19/87 [01:28<03:38,  3.22s/it]\u001b[A\n",
      "Epoch 3:  92%|▉| 723/789 [30:13<02:45,  2.51s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  92%|▉| 724/789 [30:13<02:42,  2.51s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  92%|▉| 725/789 [30:13<02:40,  2.50s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  92%|▉| 726/789 [30:14<02:37,  2.50s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  92%|▉| 727/789 [30:14<02:34,  2.50s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  92%|▉| 728/789 [30:15<02:32,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  92%|▉| 729/789 [30:15<02:29,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  93%|▉| 730/789 [30:15<02:26,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  93%|▉| 732/789 [30:15<02:21,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  34%|██████████▋                    | 30/87 [01:31<00:23,  2.40it/s]\u001b[A\n",
      "Epoch 3:  93%|▉| 734/789 [30:16<02:16,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  93%|▉| 736/789 [30:17<02:10,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  94%|▉| 738/789 [30:32<02:06,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  40%|████████████▍                  | 35/87 [01:48<00:15,  3.26it/s]\u001b[A\n",
      "Epoch 3:  94%|▉| 739/789 [30:41<02:04,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  94%|▉| 740/789 [30:41<02:01,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  94%|▉| 742/789 [30:41<01:56,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  94%|▉| 744/789 [30:42<01:51,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  48%|██████████████▉                | 42/87 [01:58<00:59,  1.33s/it]\u001b[A\n",
      "Epoch 3:  95%|▉| 746/789 [30:52<01:46,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  95%|▉| 747/789 [30:56<01:44,  2.49s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  95%|▉| 750/789 [30:56<01:36,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  56%|█████████████████▍             | 49/87 [02:13<01:00,  1.58s/it]\u001b[A\n",
      "Epoch 3:  95%|▉| 753/789 [30:57<01:28,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:13<00:38,  1.07s/it]\u001b[A\n",
      "Epoch 3:  96%|▉| 756/789 [31:04<01:21,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:20<00:48,  1.46s/it]\u001b[A\n",
      "Epoch 3:  96%|▉| 759/789 [31:22<01:14,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  96%|▉| 760/789 [31:27<01:12,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  97%|▉| 762/789 [31:27<01:06,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:44<01:10,  2.61s/it]\u001b[A\n",
      "Epoch 3:  97%|▉| 764/789 [31:28<01:01,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  97%|▉| 766/789 [31:28<00:56,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  97%|▉| 767/789 [31:42<00:54,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  97%|▉| 768/789 [31:47<00:52,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  98%|▉| 770/789 [31:49<00:47,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  98%|▉| 772/789 [31:49<00:42,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  98%|▉| 774/789 [31:49<00:37,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  98%|▉| 777/789 [32:02<00:29,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:18<00:11,  1.17it/s]\u001b[A\n",
      "Epoch 3:  99%|▉| 778/789 [32:09<00:27,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  99%|▉| 780/789 [32:14<00:22,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  99%|▉| 781/789 [32:14<00:19,  2.48s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  99%|▉| 782/789 [32:14<00:17,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  99%|▉| 783/789 [32:14<00:14,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  99%|▉| 784/789 [32:14<00:12,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3:  99%|▉| 785/789 [32:15<00:09,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3: 100%|▉| 786/789 [32:15<00:07,  2.46s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3: 100%|▉| 787/789 [32:22<00:04,  2.47s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3: 100%|▉| 788/789 [32:22<00:02,  2.46s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Epoch 3: 100%|█| 789/789 [32:22<00:00,  2.46s/it, loss=0.488, val_loss=0.651, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:38<00:00,  1.02s/it]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 3: 100%|█| 789/789 [32:22<00:00,  2.46s/it, loss=0.488, val_loss=0.798, au\n",
      "                                                                                \u001b[AEpoch 3, step 1403: val_loss was not in top 1\n",
      "Epoch 4:  89%|▉| 702/789 [28:35<03:32,  2.44s/it, loss=0.627, val_loss=0.798, auclass 0: acc 0.8506787330316742, correct 376/442\n",
      "class 1: acc 0.25769230769230766, correct 67/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  89%|▉| 704/789 [29:04<03:30,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  89%|▉| 705/789 [29:06<03:28,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  89%|▉| 706/789 [29:06<03:25,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  90%|▉| 708/789 [29:07<03:19,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:31<03:06,  2.30s/it]\u001b[A\n",
      "Epoch 4:  90%|▉| 710/789 [29:14<03:15,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  90%|▉| 712/789 [29:22<03:10,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:46<02:51,  2.25s/it]\u001b[A\n",
      "Epoch 4:  91%|▉| 715/789 [29:36<03:03,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  91%|▉| 718/789 [29:49<02:56,  2.49s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:13<03:32,  2.95s/it]\u001b[A\n",
      "Epoch 4:  91%|▉| 719/789 [29:52<02:54,  2.49s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  91%|▉| 721/789 [29:52<02:49,  2.49s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  92%|▉| 723/789 [30:04<02:44,  2.50s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  92%|▉| 725/789 [30:04<02:39,  2.49s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  92%|▉| 727/789 [30:05<02:34,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  92%|▉| 728/789 [30:05<02:31,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  92%|▉| 729/789 [30:06<02:28,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  93%|▉| 730/789 [30:06<02:25,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  93%|▉| 732/789 [30:06<02:20,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  93%|▉| 734/789 [30:06<02:15,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  94%|▉| 738/789 [30:19<02:05,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  94%|▉| 739/789 [30:33<02:04,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  94%|▉| 740/789 [30:33<02:01,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  94%|▉| 743/789 [30:33<01:53,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:57<01:11,  1.57s/it]\u001b[A\n",
      "Validating:  48%|██████████████▉                | 42/87 [01:58<00:58,  1.29s/it]\u001b[A\n",
      "Epoch 4:  95%|▉| 746/789 [30:34<01:45,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  95%|▉| 749/789 [30:49<01:38,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  95%|▉| 751/789 [30:49<01:33,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  95%|▉| 753/789 [30:50<01:28,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:14<00:45,  1.27s/it]\u001b[A\n",
      "Epoch 4:  96%|▉| 755/789 [30:57<01:23,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  96%|▉| 757/789 [30:57<01:18,  2.45s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  96%|▉| 759/789 [31:19<01:14,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  96%|▉| 760/789 [31:20<01:11,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  97%|▉| 762/789 [31:20<01:06,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:44<01:08,  2.55s/it]\u001b[A\n",
      "Epoch 4:  97%|▉| 764/789 [31:20<01:01,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  97%|▉| 767/789 [31:39<00:54,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [03:03<00:24,  1.06s/it]\u001b[A\n",
      "Epoch 4:  97%|▉| 768/789 [31:42<00:52,  2.48s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  98%|▉| 770/789 [31:43<00:46,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  98%|▉| 772/789 [31:44<00:41,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  98%|▉| 774/789 [31:44<00:36,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  98%|▉| 777/789 [31:59<00:29,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:23<00:12,  1.04it/s]\u001b[A\n",
      "Epoch 4:  99%|▉| 778/789 [32:03<00:27,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  99%|▉| 780/789 [32:08<00:22,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  99%|▉| 781/789 [32:09<00:19,  2.47s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4:  99%|▉| 783/789 [32:09<00:14,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:33<00:09,  1.56s/it]\u001b[A\n",
      "Epoch 4:  99%|▉| 785/789 [32:09<00:09,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Epoch 4: 100%|▉| 787/789 [32:16<00:04,  2.46s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:40<00:03,  1.67s/it]\u001b[A\n",
      "Epoch 4: 100%|█| 789/789 [32:16<00:00,  2.45s/it, loss=0.627, val_loss=0.798, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:41<00:00,  1.02s/it]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 4: 100%|█| 789/789 [32:17<00:00,  2.46s/it, loss=0.627, val_loss=0.659, au\n",
      "                                                                                \u001b[AEpoch 4, step 1754: val_loss was not in top 1\n",
      "Epoch 5:  89%|▉| 702/789 [28:43<03:33,  2.45s/it, loss=0.573, val_loss=0.659, auclass 0: acc 0.8642533936651584, correct 382/442\n",
      "class 1: acc 0.27307692307692305, correct 71/260\n",
      "Epoch 5:  89%|▉| 703/789 [28:43<03:30,  2.45s/it, loss=0.573, val_loss=0.659, au\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  89%|▉| 703/789 [29:02<03:33,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  89%|▉| 704/789 [29:11<03:31,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  89%|▉| 705/789 [29:13<03:28,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  89%|▉| 706/789 [29:13<03:26,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  90%|▉| 708/789 [29:14<03:20,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<03:03,  2.26s/it]\u001b[A\n",
      "Epoch 5:  90%|▉| 710/789 [29:21<03:15,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  90%|▉| 712/789 [29:30<03:11,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  90%|▉| 714/789 [29:42<03:07,  2.50s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:59<02:56,  2.33s/it]\u001b[A\n",
      "Epoch 5:  91%|▉| 715/789 [29:44<03:04,  2.50s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  91%|▉| 717/789 [29:44<02:59,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  91%|▉| 719/789 [30:00<02:55,  2.50s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  91%|▉| 721/789 [30:00<02:49,  2.50s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  92%|▉| 723/789 [30:12<02:45,  2.51s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  92%|▉| 725/789 [30:12<02:40,  2.50s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  92%|▉| 727/789 [30:13<02:34,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:30<01:42,  1.66s/it]\u001b[A\n",
      "Epoch 5:  92%|▉| 729/789 [30:14<02:29,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  93%|▉| 731/789 [30:14<02:23,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:31<00:41,  1.41it/s]\u001b[A\n",
      "Epoch 5:  93%|▉| 733/789 [30:14<02:18,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  94%|▉| 738/789 [30:32<02:06,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  94%|▉| 739/789 [30:40<02:04,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  94%|▉| 740/789 [30:40<02:01,  2.49s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  94%|▉| 743/789 [30:40<01:53,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:57<01:10,  1.52s/it]\u001b[A\n",
      "Epoch 5:  95%|▉| 746/789 [30:52<01:46,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  95%|▉| 747/789 [30:55<01:44,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  95%|▉| 751/789 [30:55<01:33,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:12<00:48,  1.32s/it]\u001b[A\n",
      "Epoch 5:  96%|▉| 755/789 [31:03<01:23,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:20<00:47,  1.43s/it]\u001b[A\n",
      "Epoch 5:  96%|▉| 759/789 [31:22<01:14,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  96%|▉| 760/789 [31:25<01:11,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  97%|▉| 762/789 [31:25<01:06,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:42<01:05,  2.43s/it]\u001b[A\n",
      "Epoch 5:  97%|▉| 764/789 [31:25<01:01,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  97%|▉| 767/789 [31:42<00:54,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:59<00:23,  1.03s/it]\u001b[A\n",
      "Epoch 5:  97%|▉| 768/789 [31:48<00:52,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  98%|▉| 770/789 [31:49<00:47,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  98%|▉| 772/789 [31:50<00:42,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  98%|▉| 774/789 [31:50<00:37,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  98%|▉| 777/789 [32:02<00:29,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:19<00:12,  1.01it/s]\u001b[A\n",
      "Epoch 5:  99%|▉| 778/789 [32:10<00:27,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  99%|▉| 780/789 [32:16<00:22,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  99%|▉| 781/789 [32:16<00:19,  2.48s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5:  99%|▉| 783/789 [32:16<00:14,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:33<00:09,  1.64s/it]\u001b[A\n",
      "Epoch 5:  99%|▉| 785/789 [32:17<00:09,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Epoch 5: 100%|▉| 787/789 [32:23<00:04,  2.47s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:40<00:03,  1.70s/it]\u001b[A\n",
      "Epoch 5: 100%|█| 789/789 [32:24<00:00,  2.46s/it, loss=0.573, val_loss=0.659, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:41<00:00,  1.03s/it]\u001b[Aclass 0: acc 0.8, correct 44/55\n",
      "class 1: acc 0.5, correct 16/32\n",
      "Epoch 5: 100%|█| 789/789 [32:24<00:00,  2.46s/it, loss=0.573, val_loss=0.638, au\n",
      "                                                                                \u001b[AEpoch 5, global step 2105: val_loss reached 0.63770 (best 0.63770), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold4/epoch=05-val_loss=0.6377.ckpt\" as top 1\n",
      "Epoch 6:  89%|▉| 702/789 [28:37<03:32,  2.45s/it, loss=0.485, val_loss=0.638, auclass 0: acc 0.8371040723981901, correct 370/442\n",
      "class 1: acc 0.4115384615384615, correct 107/260\n",
      "Epoch 6:  89%|▉| 703/789 [28:37<03:30,  2.44s/it, loss=0.485, val_loss=0.638, au\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  89%|▉| 703/789 [28:48<03:31,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  89%|▉| 704/789 [29:06<03:30,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  89%|▉| 705/789 [29:07<03:28,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  89%|▉| 706/789 [29:08<03:25,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  90%|▉| 708/789 [29:08<03:20,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<03:01,  2.24s/it]\u001b[A\n",
      "Epoch 6:  90%|▉| 710/789 [29:15<03:15,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  90%|▉| 712/789 [29:23<03:10,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:46<02:50,  2.25s/it]\u001b[A\n",
      "Epoch 6:  91%|▉| 715/789 [29:37<03:04,  2.49s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  91%|▉| 718/789 [29:48<02:56,  2.49s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:10<03:34,  2.97s/it]\u001b[A\n",
      "Epoch 6:  91%|▉| 719/789 [29:54<02:54,  2.50s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  91%|▉| 721/789 [29:54<02:49,  2.49s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  92%|▉| 723/789 [30:05<02:44,  2.50s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  92%|▉| 725/789 [30:05<02:39,  2.49s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  92%|▉| 727/789 [30:06<02:34,  2.49s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:29<01:42,  1.66s/it]\u001b[A\n",
      "Epoch 6:  92%|▉| 729/789 [30:07<02:28,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  93%|▉| 731/789 [30:07<02:23,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:29<00:41,  1.40it/s]\u001b[A\n",
      "Epoch 6:  93%|▉| 733/789 [30:07<02:18,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  94%|▉| 738/789 [30:28<02:06,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  94%|▉| 739/789 [30:32<02:03,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  94%|▉| 740/789 [30:32<02:01,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  94%|▉| 743/789 [30:33<01:53,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:55<01:07,  1.47s/it]\u001b[A\n",
      "Epoch 6:  95%|▉| 746/789 [30:48<01:46,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  49%|███████████████▎               | 43/87 [02:10<00:45,  1.04s/it]\u001b[A\n",
      "Epoch 6:  95%|▉| 747/789 [30:48<01:43,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  95%|▉| 751/789 [30:49<01:33,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:12<00:55,  1.49s/it]\u001b[A\n",
      "Epoch 6:  96%|▉| 755/789 [30:56<01:23,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:18<00:46,  1.42s/it]\u001b[A\n",
      "Epoch 6:  96%|▉| 759/789 [31:18<01:14,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  96%|▉| 760/789 [31:19<01:11,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  97%|▉| 762/789 [31:19<01:06,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:42<01:06,  2.48s/it]\u001b[A\n",
      "Epoch 6:  97%|▉| 764/789 [31:20<01:01,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  97%|▉| 767/789 [31:38<00:54,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [03:00<00:24,  1.07s/it]\u001b[A\n",
      "Epoch 6:  97%|▉| 768/789 [31:42<00:52,  2.48s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  98%|▉| 770/789 [31:43<00:46,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  98%|▉| 772/789 [31:44<00:41,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  98%|▉| 774/789 [31:44<00:36,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  98%|▉| 777/789 [31:58<00:29,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:20<00:12,  1.02it/s]\u001b[A\n",
      "Epoch 6:  99%|▉| 778/789 [32:03<00:27,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  99%|▉| 780/789 [32:08<00:22,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  99%|▉| 781/789 [32:09<00:19,  2.47s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Epoch 6:  99%|▉| 783/789 [32:09<00:14,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:31<00:09,  1.55s/it]\u001b[A\n",
      "Epoch 6:  99%|▉| 785/789 [32:09<00:09,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:32<00:04,  1.06s/it]\u001b[A\n",
      "Epoch 6: 100%|▉| 787/789 [32:16<00:04,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:39<00:03,  1.91s/it]\u001b[A\n",
      "Epoch 6: 100%|█| 789/789 [32:17<00:00,  2.46s/it, loss=0.485, val_loss=0.638, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:39<00:00,  1.06s/it]\u001b[Aclass 0: acc 0.9818181818181818, correct 54/55\n",
      "class 1: acc 0.125, correct 4/32\n",
      "Epoch 6: 100%|█| 789/789 [32:17<00:00,  2.46s/it, loss=0.485, val_loss=0.770, au\n",
      "                                                                                \u001b[AEpoch 6, step 2456: val_loss was not in top 1\n",
      "Epoch 7:  89%|▉| 702/789 [28:42<03:33,  2.45s/it, loss=0.527, val_loss=0.770, auclass 0: acc 0.8280542986425339, correct 366/442\n",
      "class 1: acc 0.49230769230769234, correct 128/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  89%|▉| 703/789 [29:00<03:32,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  89%|▉| 704/789 [29:12<03:31,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  89%|▉| 705/789 [29:14<03:29,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  89%|▉| 706/789 [29:14<03:26,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  90%|▉| 707/789 [29:14<03:23,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  90%|▉| 708/789 [29:14<03:20,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  90%|▉| 709/789 [29:15<03:18,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  90%|▉| 710/789 [29:21<03:16,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  90%|▉| 711/789 [29:30<03:14,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  90%|▉| 714/789 [29:40<03:07,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:58<02:47,  2.21s/it]\u001b[A\n",
      "Epoch 7:  91%|▉| 715/789 [29:44<03:04,  2.50s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  91%|▉| 717/789 [29:44<02:59,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  91%|▉| 719/789 [30:00<02:55,  2.50s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  91%|▉| 721/789 [30:00<02:49,  2.50s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  92%|▉| 723/789 [30:11<02:45,  2.51s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  92%|▉| 725/789 [30:12<02:39,  2.50s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  92%|▉| 727/789 [30:13<02:34,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:30<01:41,  1.63s/it]\u001b[A\n",
      "Epoch 7:  92%|▉| 729/789 [30:13<02:29,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  93%|▉| 731/789 [30:13<02:23,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:31<00:40,  1.43it/s]\u001b[A\n",
      "Epoch 7:  93%|▉| 733/789 [30:13<02:18,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  94%|▉| 738/789 [30:30<02:06,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  94%|▉| 739/789 [30:40<02:04,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  94%|▉| 740/789 [30:40<02:01,  2.49s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  94%|▉| 743/789 [30:40<01:53,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:58<01:10,  1.53s/it]\u001b[A\n",
      "Epoch 7:  95%|▉| 746/789 [30:40<01:46,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  95%|▉| 749/789 [30:56<01:39,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  95%|▉| 751/789 [30:56<01:33,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  95%|▉| 753/789 [30:57<01:28,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:15<00:46,  1.29s/it]\u001b[A\n",
      "Epoch 7:  96%|▉| 755/789 [31:03<01:23,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  96%|▉| 757/789 [31:03<01:18,  2.46s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  96%|▉| 759/789 [31:20<01:14,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  96%|▉| 760/789 [31:26<01:11,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  97%|▉| 762/789 [31:26<01:06,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:44<01:08,  2.54s/it]\u001b[A\n",
      "Epoch 7:  97%|▉| 764/789 [31:27<01:01,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  97%|▉| 767/789 [31:40<00:54,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:58<00:24,  1.06s/it]\u001b[A\n",
      "Epoch 7:  97%|▉| 768/789 [31:47<00:52,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  98%|▉| 770/789 [31:48<00:47,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  98%|▉| 772/789 [31:48<00:42,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  98%|▉| 774/789 [31:48<00:36,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  98%|▉| 777/789 [32:00<00:29,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:18<00:11,  1.12it/s]\u001b[A\n",
      "Epoch 7:  99%|▉| 778/789 [32:08<00:27,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  99%|▉| 780/789 [32:13<00:22,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  99%|▉| 781/789 [32:13<00:19,  2.48s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Epoch 7:  99%|▉| 783/789 [32:13<00:14,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:31<00:09,  1.53s/it]\u001b[A\n",
      "Epoch 7:  99%|▉| 785/789 [32:14<00:09,  2.46s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:32<00:04,  1.08s/it]\u001b[A\n",
      "Epoch 7: 100%|▉| 787/789 [32:21<00:04,  2.47s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:39<00:03,  1.90s/it]\u001b[A\n",
      "Epoch 7: 100%|█| 789/789 [32:21<00:00,  2.46s/it, loss=0.527, val_loss=0.770, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:39<00:00,  1.05s/it]\u001b[Aclass 0: acc 0.9454545454545454, correct 52/55\n",
      "class 1: acc 0.25, correct 8/32\n",
      "Epoch 7: 100%|█| 789/789 [32:21<00:00,  2.46s/it, loss=0.527, val_loss=0.639, au\n",
      "                                                                                \u001b[AEpoch 7, step 2807: val_loss was not in top 1\n",
      "Epoch 8:  89%|▉| 702/789 [28:34<03:32,  2.44s/it, loss=0.604, val_loss=0.639, auclass 0: acc 0.8868778280542986, correct 392/442\n",
      "class 1: acc 0.49230769230769234, correct 128/260\n",
      "Epoch 8:  89%|▉| 703/789 [28:34<03:29,  2.44s/it, loss=0.604, val_loss=0.639, au\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  89%|▉| 703/789 [28:48<03:31,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  89%|▉| 704/789 [29:04<03:30,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  89%|▉| 705/789 [29:05<03:28,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  89%|▉| 706/789 [29:06<03:25,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  90%|▉| 707/789 [29:06<03:22,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  90%|▉| 708/789 [29:06<03:19,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  90%|▉| 709/789 [29:06<03:17,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  90%|▉| 710/789 [29:13<03:15,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  90%|▉| 711/789 [29:22<03:13,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  90%|▉| 714/789 [29:22<03:05,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  91%|▉| 717/789 [29:35<02:58,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:01<03:04,  2.57s/it]\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:14<03:04,  2.57s/it]\u001b[A\n",
      "Epoch 8:  91%|▉| 719/789 [29:52<02:54,  2.49s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  91%|▉| 721/789 [29:53<02:49,  2.49s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  92%|▉| 723/789 [30:04<02:44,  2.50s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  92%|▉| 725/789 [30:04<02:39,  2.49s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  92%|▉| 727/789 [30:05<02:34,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:31<01:46,  1.73s/it]\u001b[A\n",
      "Epoch 8:  92%|▉| 729/789 [30:06<02:28,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  93%|▉| 731/789 [30:06<02:23,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:31<00:42,  1.37it/s]\u001b[A\n",
      "Epoch 8:  93%|▉| 733/789 [30:06<02:18,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  94%|▉| 738/789 [30:18<02:05,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  94%|▉| 739/789 [30:32<02:03,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  94%|▉| 740/789 [30:32<02:01,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  94%|▉| 743/789 [30:32<01:53,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:58<01:09,  1.51s/it]\u001b[A\n",
      "Epoch 8:  95%|▉| 746/789 [30:48<01:46,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  49%|███████████████▎               | 43/87 [02:14<00:46,  1.06s/it]\u001b[A\n",
      "Epoch 8:  95%|▉| 747/789 [30:49<01:43,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  95%|▉| 751/789 [30:49<01:33,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:16<00:59,  1.61s/it]\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:16<00:49,  1.37s/it]\u001b[A\n",
      "Epoch 8:  96%|▉| 755/789 [30:56<01:23,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:21<00:46,  1.40s/it]\u001b[A\n",
      "Epoch 8:  96%|▉| 759/789 [31:18<01:14,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  96%|▉| 760/789 [31:19<01:11,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  97%|▉| 762/789 [31:19<01:06,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:45<01:08,  2.53s/it]\u001b[A\n",
      "Epoch 8:  97%|▉| 764/789 [31:19<01:01,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  97%|▉| 767/789 [31:38<00:54,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [03:04<00:24,  1.06s/it]\u001b[A\n",
      "Epoch 8:  97%|▉| 768/789 [31:42<00:52,  2.48s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  98%|▉| 770/789 [31:43<00:46,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  98%|▉| 772/789 [31:43<00:41,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  98%|▉| 774/789 [31:43<00:36,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  98%|▉| 777/789 [31:58<00:29,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:24<00:12,  1.04it/s]\u001b[A\n",
      "Epoch 8:  99%|▉| 778/789 [32:03<00:27,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  99%|▉| 780/789 [32:08<00:22,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  99%|▉| 781/789 [32:08<00:19,  2.47s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Epoch 8:  99%|▉| 783/789 [32:09<00:14,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:34<00:09,  1.56s/it]\u001b[A\n",
      "Epoch 8:  99%|▉| 785/789 [32:09<00:09,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:35<00:04,  1.09s/it]\u001b[A\n",
      "Epoch 8: 100%|▉| 787/789 [32:16<00:04,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:42<00:03,  1.91s/it]\u001b[A\n",
      "Epoch 8: 100%|█| 789/789 [32:17<00:00,  2.46s/it, loss=0.604, val_loss=0.639, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:42<00:00,  1.06s/it]\u001b[Aclass 0: acc 0.6727272727272727, correct 37/55\n",
      "class 1: acc 0.71875, correct 23/32\n",
      "Epoch 8: 100%|█| 789/789 [32:17<00:00,  2.46s/it, loss=0.604, val_loss=0.636, au\n",
      "                                                                                \u001b[AEpoch 8, global step 3158: val_loss reached 0.63567 (best 0.63567), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold4/epoch=08-val_loss=0.6357.ckpt\" as top 1\n",
      "Epoch 9:  89%|▉| 702/789 [29:59<03:43,  2.56s/it, loss=0.603, val_loss=0.636, auclass 0: acc 0.8846153846153846, correct 391/442\n",
      "class 1: acc 0.5384615384615384, correct 140/260\n",
      "Epoch 9:  89%|▉| 703/789 [29:59<03:40,  2.56s/it, loss=0.603, val_loss=0.636, au\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  89%|▉| 703/789 [30:11<03:41,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  89%|▉| 704/789 [30:30<03:40,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  89%|▉| 705/789 [30:31<03:38,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  89%|▉| 706/789 [30:32<03:35,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  90%|▉| 707/789 [30:32<03:32,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  90%|▉| 708/789 [30:32<03:29,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  90%|▉| 709/789 [30:32<03:26,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  90%|▉| 710/789 [30:39<03:24,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  90%|▉| 711/789 [30:49<03:22,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  90%|▉| 714/789 [31:01<03:15,  2.61s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [01:01<03:08,  2.49s/it]\u001b[A\n",
      "Epoch 9:  91%|▉| 715/789 [31:05<03:13,  2.61s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  91%|▉| 718/789 [31:21<03:06,  2.62s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:21<03:53,  3.25s/it]\u001b[A\n",
      "Epoch 9:  91%|▉| 719/789 [31:22<03:03,  2.62s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  91%|▉| 721/789 [31:22<02:57,  2.61s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  92%|▉| 723/789 [31:34<02:52,  2.62s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  92%|▉| 725/789 [31:34<02:47,  2.61s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  92%|▉| 727/789 [31:36<02:41,  2.61s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:36<01:50,  1.78s/it]\u001b[A\n",
      "Epoch 9:  92%|▉| 729/789 [31:36<02:36,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  93%|▉| 731/789 [31:36<02:30,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:36<00:43,  1.32it/s]\u001b[A\n",
      "Epoch 9:  93%|▉| 733/789 [31:36<02:24,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  94%|▉| 738/789 [31:51<02:12,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  94%|▉| 739/789 [32:04<02:10,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  94%|▉| 740/789 [32:04<02:07,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  94%|▉| 742/789 [32:05<02:01,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  94%|▉| 744/789 [32:05<01:56,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  95%|▉| 746/789 [32:05<01:50,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  95%|▉| 748/789 [32:21<01:46,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  95%|▉| 751/789 [32:21<01:38,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:23<01:00,  1.63s/it]\u001b[A\n",
      "Epoch 9:  96%|▉| 754/789 [32:23<01:30,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  60%|██████████████████▌            | 52/87 [02:29<01:19,  2.28s/it]\u001b[A\n",
      "Epoch 9:  96%|▉| 757/789 [32:29<01:22,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  96%|▉| 759/789 [32:41<01:17,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  96%|▉| 760/789 [32:52<01:15,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  97%|▉| 762/789 [32:53<01:09,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:53<01:10,  2.61s/it]\u001b[A\n",
      "Epoch 9:  97%|▉| 764/789 [32:53<01:04,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  97%|▉| 767/789 [33:11<00:57,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [03:11<00:24,  1.09s/it]\u001b[A\n",
      "Epoch 9:  97%|▉| 768/789 [33:16<00:54,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  98%|▉| 770/789 [33:17<00:49,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  98%|▉| 772/789 [33:18<00:43,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  98%|▉| 774/789 [33:18<00:38,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  98%|▉| 777/789 [33:31<00:31,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:31<00:13,  1.01s/it]\u001b[A\n",
      "Epoch 9:  99%|▉| 778/789 [33:39<00:28,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  99%|▉| 780/789 [33:45<00:23,  2.60s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  99%|▉| 781/789 [33:46<00:20,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Epoch 9:  99%|▉| 783/789 [33:46<00:15,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:46<00:10,  1.72s/it]\u001b[A\n",
      "Epoch 9:  99%|▉| 785/789 [33:46<00:10,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:47<00:04,  1.15s/it]\u001b[A\n",
      "Epoch 9: 100%|▉| 787/789 [33:54<00:05,  2.59s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:55<00:04,  2.11s/it]\u001b[A\n",
      "Epoch 9: 100%|█| 789/789 [33:55<00:00,  2.58s/it, loss=0.603, val_loss=0.636, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:55<00:00,  1.16s/it]\u001b[Aclass 0: acc 0.9454545454545454, correct 52/55\n",
      "class 1: acc 0.28125, correct 9/32\n",
      "Epoch 9: 100%|█| 789/789 [33:55<00:00,  2.58s/it, loss=0.603, val_loss=0.618, au\n",
      "                                                                                \u001b[AEpoch 9, global step 3509: val_loss reached 0.61835 (best 0.61835), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold4/epoch=09-val_loss=0.6184.ckpt\" as top 1\n",
      "Epoch 10:  89%|▉| 702/789 [28:36<03:32,  2.45s/it, loss=0.599, val_loss=0.618, aclass 0: acc 0.9072398190045249, correct 401/442\n",
      "class 1: acc 0.48846153846153845, correct 127/260\n",
      "Epoch 10:  89%|▉| 703/789 [28:36<03:29,  2.44s/it, loss=0.599, val_loss=0.618, a\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  89%|▉| 703/789 [28:56<03:32,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  89%|▉| 704/789 [29:04<03:30,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  89%|▉| 705/789 [29:06<03:28,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  89%|▉| 706/789 [29:06<03:25,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  90%|▉| 708/789 [29:06<03:19,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<03:00,  2.23s/it]\u001b[A\n",
      "Epoch 10:  90%|▉| 710/789 [29:13<03:15,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  90%|▉| 712/789 [29:22<03:10,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  90%|▉| 714/789 [29:36<03:06,  2.49s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  91%|▉| 715/789 [29:36<03:03,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  91%|▉| 717/789 [29:36<02:58,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  91%|▉| 719/789 [29:52<02:54,  2.49s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  91%|▉| 721/789 [29:52<02:49,  2.49s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  92%|▉| 723/789 [30:03<02:44,  2.49s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  92%|▉| 725/789 [30:03<02:39,  2.49s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  92%|▉| 727/789 [30:05<02:33,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  92%|▉| 728/789 [30:05<02:31,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  92%|▉| 729/789 [30:05<02:28,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  93%|▉| 730/789 [30:05<02:25,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  93%|▉| 732/789 [30:05<02:20,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  93%|▉| 734/789 [30:05<02:15,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  94%|▉| 738/789 [30:26<02:06,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  94%|▉| 739/789 [30:32<02:03,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  94%|▉| 740/789 [30:32<02:01,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  94%|▉| 743/789 [30:32<01:53,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:56<01:10,  1.53s/it]\u001b[A\n",
      "Epoch 10:  95%|▉| 746/789 [30:46<01:46,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  49%|███████████████▎               | 43/87 [02:09<00:47,  1.08s/it]\u001b[A\n",
      "Epoch 10:  95%|▉| 747/789 [30:47<01:43,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  95%|▉| 751/789 [30:47<01:33,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:12<00:55,  1.50s/it]\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:12<00:45,  1.28s/it]\u001b[A\n",
      "Epoch 10:  96%|▉| 755/789 [30:55<01:23,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:18<00:46,  1.41s/it]\u001b[A\n",
      "Epoch 10:  96%|▉| 759/789 [31:16<01:14,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  96%|▉| 760/789 [31:18<01:11,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  97%|▉| 762/789 [31:18<01:06,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:42<01:08,  2.53s/it]\u001b[A\n",
      "Epoch 10:  97%|▉| 764/789 [31:18<01:01,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  97%|▉| 767/789 [31:36<00:54,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:59<00:24,  1.06s/it]\u001b[A\n",
      "Epoch 10:  97%|▉| 768/789 [31:41<00:51,  2.48s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  98%|▉| 770/789 [31:42<00:46,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  98%|▉| 772/789 [31:42<00:41,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  98%|▉| 774/789 [31:42<00:36,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  98%|▉| 777/789 [31:56<00:29,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:19<00:12,  1.04it/s]\u001b[A\n",
      "Epoch 10:  99%|▉| 778/789 [32:02<00:27,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  99%|▉| 780/789 [32:07<00:22,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  99%|▉| 781/789 [32:07<00:19,  2.47s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Epoch 10:  99%|▉| 783/789 [32:08<00:14,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:31<00:09,  1.57s/it]\u001b[A\n",
      "Epoch 10:  99%|▉| 785/789 [32:08<00:09,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:32<00:04,  1.09s/it]\u001b[A\n",
      "Epoch 10: 100%|▉| 787/789 [32:15<00:04,  2.46s/it, loss=0.599, val_loss=0.618, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:39<00:03,  1.94s/it]\u001b[A\n",
      "Epoch 10: 100%|█| 789/789 [32:16<00:00,  2.45s/it, loss=0.599, val_loss=0.618, a\u001b[Aclass 0: acc 0.9636363636363636, correct 53/55\n",
      "class 1: acc 0.4375, correct 14/32\n",
      "Epoch 10: 100%|█| 789/789 [32:16<00:00,  2.45s/it, loss=0.599, val_loss=0.596, a\n",
      "                                                                                \u001b[AEpoch 10, global step 3860: val_loss reached 0.59598 (best 0.59598), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold4/epoch=10-val_loss=0.5960.ckpt\" as top 1\n",
      "Epoch 11:  89%|▉| 702/789 [28:23<03:31,  2.43s/it, loss=0.462, val_loss=0.596, aclass 0: acc 0.8778280542986425, correct 388/442\n",
      "class 1: acc 0.5692307692307692, correct 148/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  89%|▉| 704/789 [28:53<03:29,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  89%|▉| 705/789 [28:55<03:26,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  89%|▉| 706/789 [28:55<03:24,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  90%|▉| 708/789 [28:56<03:18,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:32<03:10,  2.35s/it]\u001b[A\n",
      "Epoch 11:  90%|▉| 710/789 [29:03<03:13,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  90%|▉| 712/789 [29:11<03:09,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:47<02:50,  2.24s/it]\u001b[A\n",
      "Epoch 11:  91%|▉| 715/789 [29:25<03:02,  2.47s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  91%|▉| 718/789 [29:39<02:56,  2.48s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:15<03:34,  2.98s/it]\u001b[A\n",
      "Epoch 11:  91%|▉| 719/789 [29:41<02:53,  2.48s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  91%|▉| 721/789 [29:41<02:48,  2.47s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  92%|▉| 723/789 [29:52<02:43,  2.48s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  92%|▉| 725/789 [29:53<02:38,  2.47s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  92%|▉| 727/789 [29:54<02:33,  2.47s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:30<01:38,  1.60s/it]\u001b[A\n",
      "Epoch 11:  92%|▉| 729/789 [29:54<02:27,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  93%|▉| 731/789 [29:54<02:22,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  93%|▉| 733/789 [29:54<02:17,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  36%|███████████                    | 31/87 [01:30<00:26,  2.09it/s]\u001b[A\n",
      "Epoch 11:  94%|▉| 738/789 [30:09<02:05,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  94%|▉| 739/789 [30:21<02:03,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  94%|▉| 740/789 [30:21<02:00,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  94%|▉| 742/789 [30:21<01:55,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  94%|▉| 744/789 [30:21<01:50,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  95%|▉| 746/789 [30:21<01:45,  2.44s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  95%|▉| 748/789 [30:37<01:40,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  95%|▉| 751/789 [30:37<01:32,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  96%|▉| 754/789 [30:38<01:25,  2.44s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  60%|██████████████████▌            | 52/87 [02:21<01:11,  2.05s/it]\u001b[A\n",
      "Epoch 11:  96%|▉| 757/789 [30:45<01:18,  2.44s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  96%|▉| 759/789 [30:59<01:13,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  96%|▉| 760/789 [31:07<01:11,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  97%|▉| 762/789 [31:07<01:06,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:43<01:04,  2.39s/it]\u001b[A\n",
      "Epoch 11:  97%|▉| 764/789 [31:07<01:01,  2.44s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  97%|▉| 767/789 [31:19<00:53,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:55<00:23,  1.03s/it]\u001b[A\n",
      "Epoch 11:  97%|▉| 768/789 [31:30<00:51,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  98%|▉| 770/789 [31:31<00:46,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  98%|▉| 772/789 [31:31<00:41,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  98%|▉| 774/789 [31:31<00:36,  2.44s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  98%|▉| 777/789 [31:49<00:29,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:25<00:12,  1.03it/s]\u001b[A\n",
      "Epoch 11:  99%|▉| 778/789 [31:51<00:27,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  99%|▉| 780/789 [31:57<00:22,  2.46s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  99%|▉| 781/789 [31:57<00:19,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11:  99%|▉| 783/789 [31:57<00:14,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:33<00:09,  1.58s/it]\u001b[A\n",
      "Epoch 11:  99%|▉| 785/789 [31:57<00:09,  2.44s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Epoch 11: 100%|▉| 787/789 [32:04<00:04,  2.45s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:40<00:03,  1.67s/it]\u001b[A\n",
      "Epoch 11: 100%|█| 789/789 [32:04<00:00,  2.44s/it, loss=0.462, val_loss=0.596, a\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:41<00:00,  1.01s/it]\u001b[Aclass 0: acc 0.9636363636363636, correct 53/55\n",
      "class 1: acc 0.1875, correct 6/32\n",
      "Epoch 11: 100%|█| 789/789 [32:05<00:00,  2.44s/it, loss=0.462, val_loss=0.766, a\n",
      "                                                                                \u001b[AEpoch 11, step 4211: val_loss was not in top 1\n",
      "Epoch 12:  89%|▉| 702/789 [28:38<03:32,  2.45s/it, loss=0.513, val_loss=0.766, aclass 0: acc 0.8959276018099548, correct 396/442\n",
      "class 1: acc 0.5384615384615384, correct 140/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  89%|▉| 703/789 [28:54<03:32,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  89%|▉| 704/789 [29:07<03:30,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  89%|▉| 705/789 [29:08<03:28,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  89%|▉| 706/789 [29:08<03:25,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  90%|▉| 708/789 [29:08<03:20,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<02:59,  2.21s/it]\u001b[A\n",
      "Epoch 12:  90%|▉| 710/789 [29:15<03:15,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  90%|▉| 712/789 [29:23<03:10,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  90%|▉| 714/789 [29:34<03:06,  2.49s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:56<02:46,  2.19s/it]\u001b[A\n",
      "Epoch 12:  91%|▉| 715/789 [29:39<03:04,  2.49s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  91%|▉| 717/789 [29:39<02:58,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  91%|▉| 719/789 [29:54<02:54,  2.50s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  92%|▉| 722/789 [30:04<02:47,  2.50s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  22%|██████▊                        | 19/87 [01:26<03:30,  3.10s/it]\u001b[A\n",
      "Epoch 12:  92%|▉| 723/789 [30:06<02:44,  2.50s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  92%|▉| 725/789 [30:06<02:39,  2.49s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  92%|▉| 727/789 [30:06<02:34,  2.49s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:28<01:33,  1.51s/it]\u001b[A\n",
      "Epoch 12:  92%|▉| 729/789 [30:06<02:28,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  93%|▉| 731/789 [30:07<02:23,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  93%|▉| 733/789 [30:07<02:18,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  36%|███████████                    | 31/87 [01:29<00:25,  2.18it/s]\u001b[A\n",
      "Epoch 12:  94%|▉| 738/789 [30:24<02:06,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  94%|▉| 739/789 [30:34<02:04,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  94%|▉| 740/789 [30:34<02:01,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  94%|▉| 743/789 [30:34<01:53,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  95%|▉| 746/789 [30:34<01:45,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  95%|▉| 749/789 [30:49<01:38,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  95%|▉| 751/789 [30:50<01:33,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  95%|▉| 753/789 [30:50<01:28,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  96%|▉| 755/789 [30:58<01:23,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  96%|▉| 757/789 [30:58<01:18,  2.45s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  96%|▉| 759/789 [31:14<01:14,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  96%|▉| 760/789 [31:19<01:11,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  97%|▉| 762/789 [31:19<01:06,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:41<01:05,  2.41s/it]\u001b[A\n",
      "Epoch 12:  97%|▉| 764/789 [31:20<01:01,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  97%|▉| 767/789 [31:34<00:54,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:56<00:23,  1.04s/it]\u001b[A\n",
      "Epoch 12:  97%|▉| 768/789 [31:41<00:52,  2.48s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  98%|▉| 770/789 [31:43<00:46,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  98%|▉| 772/789 [31:43<00:41,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  98%|▉| 774/789 [31:44<00:36,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  98%|▉| 777/789 [31:54<00:29,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:16<00:12,  1.02it/s]\u001b[A\n",
      "Epoch 12:  99%|▉| 778/789 [32:03<00:27,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  99%|▉| 780/789 [32:09<00:22,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  99%|▉| 781/789 [32:09<00:19,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12:  99%|▉| 783/789 [32:10<00:14,  2.47s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:31<00:09,  1.61s/it]\u001b[A\n",
      "Epoch 12:  99%|▉| 785/789 [32:10<00:09,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Epoch 12: 100%|▉| 787/789 [32:16<00:04,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:38<00:03,  1.62s/it]\u001b[A\n",
      "Epoch 12: 100%|█| 789/789 [32:17<00:00,  2.46s/it, loss=0.513, val_loss=0.766, a\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:38<00:00,  1.01it/s]\u001b[Aclass 0: acc 0.7090909090909091, correct 39/55\n",
      "class 1: acc 0.65625, correct 21/32\n",
      "Epoch 12: 100%|█| 789/789 [32:17<00:00,  2.46s/it, loss=0.513, val_loss=0.733, a\n",
      "                                                                                \u001b[AEpoch 12, step 4562: val_loss was not in top 1\n",
      "Epoch 13:  89%|▉| 702/789 [28:30<03:32,  2.44s/it, loss=0.51, val_loss=0.733, auclass 0: acc 0.8914027149321267, correct 394/442\n",
      "class 1: acc 0.5923076923076923, correct 154/260\n",
      "Epoch 13:  89%|▉| 703/789 [28:30<03:29,  2.43s/it, loss=0.51, val_loss=0.733, au\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  89%|▉| 703/789 [28:47<03:31,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  89%|▉| 704/789 [28:58<03:29,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  89%|▉| 705/789 [29:00<03:27,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  89%|▉| 706/789 [29:00<03:24,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  90%|▉| 708/789 [29:00<03:19,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:29<02:55,  2.17s/it]\u001b[A\n",
      "Epoch 13:  90%|▉| 710/789 [29:07<03:14,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  90%|▉| 712/789 [29:16<03:09,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  90%|▉| 714/789 [29:27<03:05,  2.48s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  91%|▉| 715/789 [29:30<03:03,  2.48s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  91%|▉| 717/789 [29:30<02:57,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  91%|▉| 719/789 [29:46<02:53,  2.48s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  92%|▉| 722/789 [29:57<02:46,  2.49s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  22%|██████▊                        | 19/87 [01:26<03:33,  3.14s/it]\u001b[A\n",
      "Epoch 13:  92%|▉| 723/789 [29:57<02:44,  2.49s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  92%|▉| 725/789 [29:58<02:38,  2.48s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  92%|▉| 727/789 [29:58<02:33,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  92%|▉| 728/789 [29:58<02:30,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  92%|▉| 729/789 [29:58<02:28,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  93%|▉| 730/789 [29:58<02:25,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  93%|▉| 732/789 [29:59<02:20,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  93%|▉| 734/789 [29:59<02:14,  2.45s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  94%|▉| 738/789 [30:17<02:05,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  94%|▉| 739/789 [30:26<02:03,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  94%|▉| 740/789 [30:26<02:00,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  94%|▉| 743/789 [30:26<01:53,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  95%|▉| 746/789 [30:37<01:45,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  49%|███████████████▎               | 43/87 [02:06<01:01,  1.40s/it]\u001b[A\n",
      "Epoch 13:  95%|▉| 747/789 [30:42<01:43,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  95%|▉| 751/789 [30:43<01:33,  2.45s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:13<00:56,  1.54s/it]\u001b[A\n",
      "Epoch 13:  96%|▉| 755/789 [30:50<01:23,  2.45s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:20<00:49,  1.50s/it]\u001b[A\n",
      "Epoch 13:  96%|▉| 759/789 [31:07<01:13,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  96%|▉| 760/789 [31:14<01:11,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  97%|▉| 762/789 [31:14<01:06,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:44<01:08,  2.55s/it]\u001b[A\n",
      "Epoch 13:  97%|▉| 764/789 [31:15<01:01,  2.45s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  97%|▉| 767/789 [31:27<00:54,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:56<00:25,  1.11s/it]\u001b[A\n",
      "Epoch 13:  97%|▉| 768/789 [31:38<00:51,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  98%|▉| 770/789 [31:40<00:46,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  98%|▉| 772/789 [31:40<00:41,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  98%|▉| 774/789 [31:40<00:36,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  98%|▉| 777/789 [31:57<00:29,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:26<00:13,  1.02s/it]\u001b[A\n",
      "Epoch 13:  99%|▉| 778/789 [32:00<00:27,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  99%|▉| 780/789 [32:04<00:22,  2.47s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  99%|▉| 781/789 [32:05<00:19,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Epoch 13:  99%|▉| 783/789 [32:05<00:14,  2.46s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:34<00:09,  1.55s/it]\u001b[A\n",
      "Epoch 13:  99%|▉| 785/789 [32:05<00:09,  2.45s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:35<00:04,  1.08s/it]\u001b[A\n",
      "Epoch 13: 100%|▉| 787/789 [32:11<00:04,  2.45s/it, loss=0.51, val_loss=0.733, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:41<00:03,  1.72s/it]\u001b[A\n",
      "Epoch 13: 100%|█| 789/789 [32:12<00:00,  2.45s/it, loss=0.51, val_loss=0.733, au\u001b[Aclass 0: acc 0.8, correct 44/55\n",
      "class 1: acc 0.53125, correct 17/32\n",
      "Epoch 13: 100%|█| 789/789 [32:12<00:00,  2.45s/it, loss=0.51, val_loss=0.661, au\n",
      "                                                                                \u001b[AEpoch 13, step 4913: val_loss was not in top 1\n",
      "Epoch 14:  89%|▉| 702/789 [28:29<03:31,  2.43s/it, loss=0.423, val_loss=0.661, aclass 0: acc 0.9049773755656109, correct 400/442\n",
      "class 1: acc 0.5923076923076923, correct 154/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  89%|▉| 703/789 [28:45<03:31,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  89%|▉| 704/789 [28:57<03:29,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  89%|▉| 705/789 [28:59<03:27,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  89%|▉| 706/789 [28:59<03:24,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  90%|▉| 708/789 [28:59<03:19,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<02:58,  2.21s/it]\u001b[A\n",
      "Epoch 14:  90%|▉| 710/789 [29:07<03:14,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  90%|▉| 712/789 [29:11<03:09,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  90%|▉| 714/789 [29:25<03:05,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:56<02:17,  1.81s/it]\u001b[A\n",
      "Epoch 14:  91%|▉| 715/789 [29:31<03:03,  2.48s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  91%|▉| 717/789 [29:31<02:57,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  91%|▉| 719/789 [29:42<02:53,  2.48s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  92%|▉| 722/789 [29:55<02:46,  2.49s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  22%|██████▊                        | 19/87 [01:26<03:08,  2.77s/it]\u001b[A\n",
      "Epoch 14:  92%|▉| 723/789 [29:56<02:44,  2.49s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  92%|▉| 725/789 [29:56<02:38,  2.48s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  92%|▉| 727/789 [29:57<02:33,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  92%|▉| 728/789 [29:57<02:30,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  92%|▉| 729/789 [29:57<02:27,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  93%|▉| 730/789 [29:57<02:25,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  93%|▉| 732/789 [29:57<02:19,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  93%|▉| 734/789 [29:58<02:14,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  94%|▉| 738/789 [30:15<02:05,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  40%|████████████▍                  | 35/87 [01:46<00:19,  2.67it/s]\u001b[A\n",
      "Epoch 14:  94%|▉| 739/789 [30:24<02:03,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  94%|▉| 740/789 [30:25<02:00,  2.47s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  94%|▉| 743/789 [30:25<01:53,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  95%|▉| 746/789 [30:25<01:45,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  95%|▉| 749/789 [30:40<01:38,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  95%|▉| 751/789 [30:40<01:33,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  95%|▉| 753/789 [30:41<01:28,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  96%|▉| 755/789 [30:48<01:23,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  96%|▉| 757/789 [30:48<01:18,  2.44s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  96%|▉| 759/789 [31:05<01:13,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  96%|▉| 760/789 [31:10<01:11,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  97%|▉| 762/789 [31:10<01:06,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:41<01:03,  2.34s/it]\u001b[A\n",
      "Epoch 14:  97%|▉| 764/789 [31:10<01:01,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  97%|▉| 767/789 [31:25<00:54,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:56<00:23,  1.02s/it]\u001b[A\n",
      "Epoch 14:  97%|▉| 768/789 [31:30<00:51,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  98%|▉| 770/789 [31:32<00:46,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  98%|▉| 772/789 [31:32<00:41,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  98%|▉| 774/789 [31:32<00:36,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  98%|▉| 777/789 [31:45<00:29,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:16<00:12,  1.08it/s]\u001b[A\n",
      "Epoch 14:  99%|▉| 778/789 [31:52<00:27,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  99%|▉| 780/789 [31:57<00:22,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  99%|▉| 781/789 [31:57<00:19,  2.46s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Epoch 14:  99%|▉| 783/789 [31:57<00:14,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:28<00:09,  1.52s/it]\u001b[A\n",
      "Epoch 14:  99%|▉| 785/789 [31:57<00:09,  2.44s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:29<00:04,  1.11s/it]\u001b[A\n",
      "Epoch 14: 100%|▉| 787/789 [32:05<00:04,  2.45s/it, loss=0.423, val_loss=0.661, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:36<00:03,  1.94s/it]\u001b[A\n",
      "Epoch 14: 100%|█| 789/789 [32:05<00:00,  2.44s/it, loss=0.423, val_loss=0.661, a\u001b[Aclass 0: acc 0.8727272727272727, correct 48/55\n",
      "class 1: acc 0.53125, correct 17/32\n",
      "Epoch 14: 100%|█| 789/789 [32:06<00:00,  2.44s/it, loss=0.423, val_loss=0.615, a\n",
      "                                                                                \u001b[AEpoch 14, step 5264: val_loss was not in top 1\n",
      "Epoch 15:  89%|▉| 702/789 [28:25<03:31,  2.43s/it, loss=0.555, val_loss=0.615, aclass 0: acc 0.9276018099547512, correct 410/442\n",
      "class 1: acc 0.6115384615384616, correct 159/260\n",
      "Epoch 15:  89%|▉| 703/789 [28:25<03:28,  2.43s/it, loss=0.555, val_loss=0.615, a\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  89%|▉| 703/789 [28:38<03:30,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  89%|▉| 704/789 [28:53<03:29,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  89%|▉| 705/789 [28:54<03:26,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  89%|▉| 706/789 [28:54<03:23,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  90%|▉| 708/789 [28:55<03:18,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<02:57,  2.20s/it]\u001b[A\n",
      "Epoch 15:  90%|▉| 710/789 [29:02<03:13,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  90%|▉| 712/789 [29:08<03:09,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  90%|▉| 714/789 [29:18<03:04,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:53<02:25,  1.91s/it]\u001b[A\n",
      "Epoch 15:  91%|▉| 715/789 [29:26<03:02,  2.47s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  91%|▉| 717/789 [29:26<02:57,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  91%|▉| 719/789 [29:38<02:53,  2.47s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  92%|▉| 722/789 [29:48<02:46,  2.48s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  22%|██████▊                        | 19/87 [01:23<03:10,  2.80s/it]\u001b[A\n",
      "Epoch 15:  92%|▉| 723/789 [29:52<02:43,  2.48s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  92%|▉| 725/789 [29:52<02:38,  2.47s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  92%|▉| 727/789 [29:52<02:32,  2.47s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  92%|▉| 728/789 [29:52<02:30,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  92%|▉| 729/789 [29:53<02:27,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  93%|▉| 730/789 [29:53<02:24,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  93%|▉| 732/789 [29:53<02:19,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  93%|▉| 734/789 [29:53<02:14,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  94%|▉| 738/789 [30:08<02:05,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  40%|████████████▍                  | 35/87 [01:43<00:12,  4.03it/s]\u001b[A\n",
      "Epoch 15:  94%|▉| 739/789 [30:19<02:03,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  94%|▉| 740/789 [30:19<02:00,  2.46s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  94%|▉| 743/789 [30:19<01:52,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  95%|▉| 746/789 [30:20<01:44,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  95%|▉| 749/789 [30:35<01:38,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  95%|▉| 751/789 [30:35<01:32,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  95%|▉| 753/789 [30:36<01:27,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  96%|▉| 755/789 [30:43<01:23,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  96%|▉| 757/789 [30:43<01:17,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  96%|▉| 759/789 [30:58<01:13,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  96%|▉| 760/789 [31:04<01:11,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  97%|▉| 762/789 [31:05<01:06,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:40<01:03,  2.34s/it]\u001b[A\n",
      "Epoch 15:  97%|▉| 764/789 [31:05<01:01,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  97%|▉| 767/789 [31:18<00:53,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:53<00:23,  1.03s/it]\u001b[A\n",
      "Epoch 15:  97%|▉| 768/789 [31:25<00:51,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  98%|▉| 770/789 [31:26<00:46,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  98%|▉| 772/789 [31:26<00:41,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  98%|▉| 774/789 [31:26<00:36,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  98%|▉| 777/789 [31:38<00:29,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:13<00:11,  1.16it/s]\u001b[A\n",
      "Epoch 15:  99%|▉| 778/789 [31:46<00:26,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  99%|▉| 780/789 [31:52<00:22,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  99%|▉| 781/789 [31:52<00:19,  2.45s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15:  99%|▉| 783/789 [31:52<00:14,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:27<00:09,  1.61s/it]\u001b[A\n",
      "Epoch 15:  99%|▉| 785/789 [31:53<00:09,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Epoch 15: 100%|▉| 787/789 [31:59<00:04,  2.44s/it, loss=0.555, val_loss=0.615, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:35<00:03,  1.70s/it]\u001b[A\n",
      "Epoch 15: 100%|█| 789/789 [32:00<00:00,  2.43s/it, loss=0.555, val_loss=0.615, a\u001b[Aclass 0: acc 0.8909090909090909, correct 49/55\n",
      "class 1: acc 0.375, correct 12/32\n",
      "Epoch 15: 100%|█| 789/789 [32:00<00:00,  2.43s/it, loss=0.555, val_loss=0.620, a\n",
      "                                                                                \u001b[AEpoch 15, step 5615: val_loss was not in top 1\n",
      "Epoch 16:  89%|▉| 702/789 [28:41<03:33,  2.45s/it, loss=0.376, val_loss=0.620, aclass 0: acc 0.9276018099547512, correct 410/442\n",
      "class 1: acc 0.6538461538461539, correct 170/260\n",
      "Epoch 16:  89%|▉| 703/789 [28:41<03:30,  2.45s/it, loss=0.376, val_loss=0.620, a\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  89%|▉| 703/789 [28:58<03:32,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  89%|▉| 704/789 [29:09<03:31,  2.49s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  89%|▉| 705/789 [29:11<03:28,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  89%|▉| 706/789 [29:11<03:25,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  90%|▉| 708/789 [29:12<03:20,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<03:01,  2.24s/it]\u001b[A\n",
      "Epoch 16:  90%|▉| 710/789 [29:19<03:15,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  90%|▉| 712/789 [29:27<03:11,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  90%|▉| 714/789 [29:38<03:06,  2.49s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  91%|▉| 715/789 [29:40<03:04,  2.49s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  91%|▉| 717/789 [29:41<02:58,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  91%|▉| 719/789 [29:56<02:54,  2.50s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  92%|▉| 722/789 [30:08<02:47,  2.50s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  22%|██████▊                        | 19/87 [01:26<03:31,  3.11s/it]\u001b[A\n",
      "Epoch 16:  92%|▉| 723/789 [30:08<02:45,  2.50s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  92%|▉| 725/789 [30:08<02:39,  2.49s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  92%|▉| 727/789 [30:09<02:34,  2.49s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:28<01:38,  1.58s/it]\u001b[A\n",
      "Epoch 16:  92%|▉| 729/789 [30:09<02:28,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  93%|▉| 731/789 [30:10<02:23,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:28<00:39,  1.47it/s]\u001b[A\n",
      "Epoch 16:  93%|▉| 733/789 [30:10<02:18,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  94%|▉| 738/789 [30:28<02:06,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  94%|▉| 739/789 [30:38<02:04,  2.49s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  94%|▉| 740/789 [30:38<02:01,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  94%|▉| 743/789 [30:38<01:53,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:57<01:14,  1.62s/it]\u001b[A\n",
      "Epoch 16:  95%|▉| 746/789 [30:38<01:45,  2.46s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  95%|▉| 749/789 [30:54<01:39,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  95%|▉| 751/789 [30:54<01:33,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  95%|▉| 753/789 [30:55<01:28,  2.46s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:14<00:45,  1.28s/it]\u001b[A\n",
      "Epoch 16:  96%|▉| 755/789 [31:02<01:23,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  96%|▉| 757/789 [31:02<01:18,  2.46s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  96%|▉| 759/789 [31:18<01:14,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  96%|▉| 760/789 [31:26<01:11,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  97%|▉| 762/789 [31:26<01:06,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:45<01:12,  2.68s/it]\u001b[A\n",
      "Epoch 16:  97%|▉| 764/789 [31:27<01:01,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  97%|▉| 767/789 [31:38<00:54,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:56<00:25,  1.12s/it]\u001b[A\n",
      "Epoch 16:  97%|▉| 768/789 [31:50<00:52,  2.49s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  98%|▉| 770/789 [31:51<00:47,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  98%|▉| 772/789 [31:52<00:42,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  98%|▉| 774/789 [31:52<00:37,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  98%|▉| 777/789 [32:08<00:29,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:26<00:13,  1.02s/it]\u001b[A\n",
      "Epoch 16:  99%|▉| 778/789 [32:12<00:27,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  99%|▉| 780/789 [32:17<00:22,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  99%|▉| 781/789 [32:17<00:19,  2.48s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Epoch 16:  99%|▉| 783/789 [32:17<00:14,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:36<00:09,  1.58s/it]\u001b[A\n",
      "Epoch 16:  99%|▉| 785/789 [32:17<00:09,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:36<00:04,  1.09s/it]\u001b[A\n",
      "Epoch 16: 100%|▉| 787/789 [32:25<00:04,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:43<00:03,  1.89s/it]\u001b[A\n",
      "Epoch 16: 100%|█| 789/789 [32:25<00:00,  2.47s/it, loss=0.376, val_loss=0.620, a\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [03:44<00:00,  1.05s/it]\u001b[Aclass 0: acc 0.9818181818181818, correct 54/55\n",
      "class 1: acc 0.15625, correct 5/32\n",
      "Epoch 16: 100%|█| 789/789 [32:25<00:00,  2.47s/it, loss=0.376, val_loss=0.843, a\n",
      "                                                                                \u001b[AEpoch 16, step 5966: val_loss was not in top 1\n",
      "Epoch 17:  89%|▉| 702/789 [28:20<03:30,  2.42s/it, loss=0.447, val_loss=0.843, aclass 0: acc 0.9230769230769231, correct 408/442\n",
      "class 1: acc 0.6653846153846154, correct 173/260\n",
      "Epoch 17:  89%|▉| 703/789 [28:20<03:28,  2.42s/it, loss=0.447, val_loss=0.843, a\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  89%|▉| 703/789 [28:32<03:29,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  89%|▉| 704/789 [28:48<03:28,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  89%|▉| 705/789 [28:49<03:26,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  89%|▉| 706/789 [28:49<03:23,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  90%|▉| 708/789 [28:50<03:17,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:29<02:56,  2.18s/it]\u001b[A\n",
      "Epoch 17:  90%|▉| 710/789 [28:57<03:13,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  90%|▉| 712/789 [29:06<03:08,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:45<02:53,  2.28s/it]\u001b[A\n",
      "Epoch 17:  91%|▉| 715/789 [29:20<03:02,  2.46s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  91%|▉| 718/789 [29:32<02:55,  2.47s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:12<03:34,  2.99s/it]\u001b[A\n",
      "Epoch 17:  91%|▉| 719/789 [29:36<02:52,  2.47s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  91%|▉| 721/789 [29:36<02:47,  2.46s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  92%|▉| 723/789 [29:48<02:43,  2.47s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  92%|▉| 725/789 [29:48<02:37,  2.47s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  92%|▉| 727/789 [29:49<02:32,  2.46s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:29<01:44,  1.69s/it]\u001b[A\n",
      "Epoch 17:  92%|▉| 729/789 [29:50<02:27,  2.46s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  93%|▉| 731/789 [29:50<02:22,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:30<00:42,  1.38it/s]\u001b[A\n",
      "Epoch 17:  93%|▉| 733/789 [29:50<02:16,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  94%|▉| 738/789 [30:02<02:04,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  94%|▉| 739/789 [30:16<02:02,  2.46s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  94%|▉| 740/789 [30:16<02:00,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  94%|▉| 743/789 [30:16<01:52,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:56<01:10,  1.52s/it]\u001b[A\n",
      "Epoch 17:  95%|▉| 746/789 [30:16<01:44,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  95%|▉| 749/789 [30:32<01:37,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  95%|▉| 751/789 [30:32<01:32,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  95%|▉| 753/789 [30:34<01:27,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:13<00:48,  1.35s/it]\u001b[A\n",
      "Epoch 17:  96%|▉| 755/789 [30:40<01:22,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  96%|▉| 757/789 [30:40<01:17,  2.43s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  96%|▉| 759/789 [31:02<01:13,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  96%|▉| 760/789 [31:04<01:11,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  97%|▉| 762/789 [31:04<01:06,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:44<01:12,  2.69s/it]\u001b[A\n",
      "Epoch 17:  97%|▉| 764/789 [31:05<01:01,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  97%|▉| 767/789 [31:22<00:54,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [03:02<00:25,  1.12s/it]\u001b[A\n",
      "Epoch 17:  97%|▉| 768/789 [31:26<00:51,  2.46s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  98%|▉| 770/789 [31:28<00:46,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  98%|▉| 772/789 [31:28<00:41,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  98%|▉| 774/789 [31:28<00:36,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  98%|▉| 777/789 [31:42<00:29,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:22<00:12,  1.04it/s]\u001b[A\n",
      "Epoch 17:  99%|▉| 778/789 [31:49<00:26,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  99%|▉| 780/789 [31:53<00:22,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  99%|▉| 781/789 [31:53<00:19,  2.45s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Epoch 17:  99%|▉| 783/789 [31:54<00:14,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:34<00:09,  1.57s/it]\u001b[A\n",
      "Epoch 17:  99%|▉| 785/789 [31:54<00:09,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:34<00:04,  1.13s/it]\u001b[A\n",
      "Epoch 17: 100%|▉| 787/789 [32:01<00:04,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:41<00:03,  1.94s/it]\u001b[A\n",
      "Epoch 17: 100%|█| 789/789 [32:02<00:00,  2.44s/it, loss=0.447, val_loss=0.843, a\u001b[Aclass 0: acc 0.8363636363636363, correct 46/55\n",
      "class 1: acc 0.53125, correct 17/32\n",
      "Epoch 17: 100%|█| 789/789 [32:02<00:00,  2.44s/it, loss=0.447, val_loss=0.686, a\n",
      "                                                                                \u001b[AEpoch 17, step 6317: val_loss was not in top 1\n",
      "Epoch 18:  89%|▉| 702/789 [28:48<03:34,  2.46s/it, loss=0.345, val_loss=0.686, aclass 0: acc 0.9389140271493213, correct 415/442\n",
      "class 1: acc 0.6961538461538461, correct 181/260\n",
      "Epoch 18:  89%|▉| 703/789 [28:48<03:31,  2.46s/it, loss=0.345, val_loss=0.686, a\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  89%|▉| 703/789 [29:00<03:32,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  89%|▉| 704/789 [29:16<03:32,  2.50s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  89%|▉| 705/789 [29:18<03:29,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  89%|▉| 706/789 [29:18<03:26,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  90%|▉| 708/789 [29:18<03:21,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:29<02:56,  2.18s/it]\u001b[A\n",
      "Epoch 18:  90%|▉| 710/789 [29:26<03:16,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  90%|▉| 712/789 [29:34<03:11,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:45<02:51,  2.26s/it]\u001b[A\n",
      "Epoch 18:  91%|▉| 715/789 [29:48<03:05,  2.50s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  91%|▉| 718/789 [30:00<02:58,  2.51s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:11<03:34,  2.97s/it]\u001b[A\n",
      "Epoch 18:  91%|▉| 719/789 [30:05<02:55,  2.51s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  91%|▉| 721/789 [30:05<02:50,  2.50s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  92%|▉| 723/789 [30:16<02:45,  2.51s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  92%|▉| 725/789 [30:17<02:40,  2.51s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  92%|▉| 727/789 [30:18<02:35,  2.50s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:29<01:43,  1.67s/it]\u001b[A\n",
      "Epoch 18:  92%|▉| 729/789 [30:18<02:29,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  93%|▉| 731/789 [30:18<02:24,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:29<00:41,  1.40it/s]\u001b[A\n",
      "Epoch 18:  93%|▉| 733/789 [30:19<02:18,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  94%|▉| 738/789 [30:40<02:07,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  94%|▉| 739/789 [30:44<02:04,  2.50s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  94%|▉| 740/789 [30:44<02:02,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  94%|▉| 743/789 [30:44<01:54,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:56<01:08,  1.50s/it]\u001b[A\n",
      "Epoch 18:  95%|▉| 746/789 [31:00<01:47,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  95%|▉| 747/789 [31:01<01:44,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  95%|▉| 751/789 [31:01<01:34,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:13<00:56,  1.53s/it]\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:13<00:47,  1.31s/it]\u001b[A\n",
      "Epoch 18:  96%|▉| 755/789 [31:08<01:24,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:19<00:47,  1.44s/it]\u001b[A\n",
      "Epoch 18:  96%|▉| 759/789 [31:30<01:14,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  96%|▉| 760/789 [31:31<01:12,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  97%|▉| 762/789 [31:31<01:07,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:43<01:08,  2.53s/it]\u001b[A\n",
      "Epoch 18:  97%|▉| 764/789 [31:32<01:01,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  97%|▉| 767/789 [31:50<00:54,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [03:01<00:24,  1.06s/it]\u001b[A\n",
      "Epoch 18:  97%|▉| 768/789 [31:54<00:52,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  98%|▉| 770/789 [31:55<00:47,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  98%|▉| 772/789 [31:55<00:42,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  98%|▉| 774/789 [31:56<00:37,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  98%|▉| 777/789 [32:10<00:29,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:21<00:12,  1.03it/s]\u001b[A\n",
      "Epoch 18:  99%|▉| 778/789 [32:16<00:27,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  99%|▉| 780/789 [32:21<00:22,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  99%|▉| 781/789 [32:21<00:19,  2.49s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Epoch 18:  99%|▉| 783/789 [32:21<00:14,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:32<00:09,  1.57s/it]\u001b[A\n",
      "Epoch 18:  99%|▉| 785/789 [32:21<00:09,  2.47s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:33<00:04,  1.05s/it]\u001b[A\n",
      "Epoch 18: 100%|▉| 787/789 [32:29<00:04,  2.48s/it, loss=0.345, val_loss=0.686, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:40<00:03,  1.90s/it]\u001b[A\n",
      "Epoch 18: 100%|█| 789/789 [32:29<00:00,  2.47s/it, loss=0.345, val_loss=0.686, a\u001b[Aclass 0: acc 0.9090909090909091, correct 50/55\n",
      "class 1: acc 0.375, correct 12/32\n",
      "Epoch 18: 100%|█| 789/789 [32:29<00:00,  2.47s/it, loss=0.345, val_loss=0.714, a\n",
      "                                                                                \u001b[AEpoch 18, step 6668: val_loss was not in top 1\n",
      "Epoch 19:  89%|▉| 702/789 [28:33<03:32,  2.44s/it, loss=0.323, val_loss=0.714, aclass 0: acc 0.9411764705882353, correct 416/442\n",
      "class 1: acc 0.676923076923077, correct 176/260\n",
      "Epoch 19:  89%|▉| 703/789 [28:33<03:29,  2.44s/it, loss=0.323, val_loss=0.714, a\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  89%|▉| 703/789 [28:50<03:31,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  89%|▉| 704/789 [29:01<03:30,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  89%|▉| 705/789 [29:02<03:27,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  89%|▉| 706/789 [29:03<03:24,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  90%|▉| 708/789 [29:03<03:19,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:30<02:59,  2.21s/it]\u001b[A\n",
      "Epoch 19:  90%|▉| 710/789 [29:10<03:14,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  90%|▉| 712/789 [29:19<03:10,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  90%|▉| 714/789 [29:30<03:05,  2.48s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:57<02:53,  2.29s/it]\u001b[A\n",
      "Epoch 19:  91%|▉| 715/789 [29:33<03:03,  2.48s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  91%|▉| 717/789 [29:33<02:58,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  91%|▉| 719/789 [29:49<02:54,  2.49s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  92%|▉| 722/789 [30:00<02:47,  2.49s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  22%|██████▊                        | 19/87 [01:27<03:39,  3.22s/it]\u001b[A\n",
      "Epoch 19:  92%|▉| 723/789 [30:01<02:44,  2.49s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  92%|▉| 725/789 [30:01<02:39,  2.48s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  92%|▉| 727/789 [30:02<02:33,  2.48s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  29%|████████▉                      | 25/87 [01:29<01:42,  1.65s/it]\u001b[A\n",
      "Epoch 19:  92%|▉| 729/789 [30:02<02:28,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  93%|▉| 731/789 [30:03<02:23,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  33%|██████████▎                    | 29/87 [01:29<00:41,  1.40it/s]\u001b[A\n",
      "Epoch 19:  93%|▉| 733/789 [30:03<02:17,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  94%|▉| 738/789 [30:20<02:05,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  94%|▉| 739/789 [30:29<02:03,  2.48s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  94%|▉| 740/789 [30:29<02:01,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  94%|▉| 743/789 [30:29<01:53,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:56<01:09,  1.52s/it]\u001b[A\n",
      "Epoch 19:  95%|▉| 746/789 [30:40<01:46,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  49%|███████████████▎               | 43/87 [02:07<00:46,  1.07s/it]\u001b[A\n",
      "Epoch 19:  95%|▉| 747/789 [30:44<01:43,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  95%|▉| 751/789 [30:44<01:33,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:12<00:53,  1.44s/it]\u001b[A\n",
      "Epoch 19:  96%|▉| 755/789 [30:52<01:23,  2.45s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:18<00:45,  1.39s/it]\u001b[A\n",
      "Epoch 19:  96%|▉| 759/789 [31:10<01:13,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  96%|▉| 760/789 [31:15<01:11,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  97%|▉| 762/789 [31:15<01:06,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:42<01:07,  2.49s/it]\u001b[A\n",
      "Epoch 19:  97%|▉| 764/789 [31:15<01:01,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  97%|▉| 767/789 [31:30<00:54,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [02:57<00:24,  1.08s/it]\u001b[A\n",
      "Epoch 19:  97%|▉| 768/789 [31:38<00:51,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  98%|▉| 770/789 [31:39<00:46,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  98%|▉| 772/789 [31:39<00:41,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  98%|▉| 774/789 [31:39<00:36,  2.45s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  98%|▉| 777/789 [31:50<00:29,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:17<00:12,  1.03it/s]\u001b[A\n",
      "Epoch 19:  99%|▉| 778/789 [31:59<00:27,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  99%|▉| 780/789 [32:04<00:22,  2.47s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  99%|▉| 781/789 [32:04<00:19,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Epoch 19:  99%|▉| 783/789 [32:04<00:14,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:31<00:09,  1.56s/it]\u001b[A\n",
      "Epoch 19:  99%|▉| 785/789 [32:05<00:09,  2.45s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:32<00:04,  1.08s/it]\u001b[A\n",
      "Epoch 19: 100%|▉| 787/789 [32:12<00:04,  2.46s/it, loss=0.323, val_loss=0.714, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:39<00:03,  1.92s/it]\u001b[A\n",
      "Epoch 19: 100%|█| 789/789 [32:12<00:00,  2.45s/it, loss=0.323, val_loss=0.714, a\u001b[Aclass 0: acc 0.6909090909090909, correct 38/55\n",
      "class 1: acc 0.5625, correct 18/32\n",
      "Epoch 19: 100%|█| 789/789 [32:13<00:00,  2.45s/it, loss=0.323, val_loss=0.772, a\n",
      "                                                                                \u001b[AEpoch 19, step 7019: val_loss was not in top 1\n",
      "Epoch 20:  89%|▉| 702/789 [28:36<03:32,  2.44s/it, loss=0.244, val_loss=0.772, aclass 0: acc 0.920814479638009, correct 407/442\n",
      "class 1: acc 0.6884615384615385, correct 179/260\n",
      "Epoch 20:  89%|▉| 703/789 [28:36<03:29,  2.44s/it, loss=0.244, val_loss=0.772, a\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  89%|▉| 703/789 [28:47<03:31,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  89%|▉| 704/789 [29:05<03:30,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  89%|▉| 705/789 [29:07<03:28,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  89%|▉| 706/789 [29:07<03:25,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  90%|▉| 708/789 [29:07<03:19,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:   7%|██▏                             | 6/87 [00:31<03:04,  2.28s/it]\u001b[A\n",
      "Epoch 20:  90%|▉| 710/789 [29:14<03:15,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  90%|▉| 712/789 [29:23<03:10,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  91%|▉| 715/789 [29:37<03:03,  2.49s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  91%|▉| 717/789 [29:37<02:58,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  91%|▉| 718/789 [29:47<02:56,  2.49s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  17%|█████▎                         | 15/87 [01:11<03:10,  2.64s/it]\u001b[A\n",
      "Epoch 20:  91%|▉| 719/789 [29:53<02:54,  2.49s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  91%|▉| 721/789 [29:53<02:49,  2.49s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  92%|▉| 723/789 [30:05<02:44,  2.50s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  92%|▉| 725/789 [30:05<02:39,  2.49s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  92%|▉| 727/789 [30:06<02:34,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  92%|▉| 728/789 [30:06<02:31,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  92%|▉| 729/789 [30:06<02:28,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  93%|▉| 730/789 [30:06<02:26,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  93%|▉| 732/789 [30:06<02:20,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  93%|▉| 734/789 [30:07<02:15,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  94%|▉| 738/789 [30:27<02:06,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  94%|▉| 739/789 [30:33<02:04,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  94%|▉| 740/789 [30:33<02:01,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  94%|▉| 743/789 [30:33<01:53,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  47%|██████████████▌                | 41/87 [01:57<01:11,  1.56s/it]\u001b[A\n",
      "Epoch 20:  95%|▉| 746/789 [30:47<01:46,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  95%|▉| 747/789 [30:49<01:43,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  95%|▉| 751/789 [30:49<01:33,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  57%|█████████████████▊             | 50/87 [02:14<00:54,  1.47s/it]\u001b[A\n",
      "Validating:  59%|██████████████████▏            | 51/87 [02:14<00:45,  1.25s/it]\u001b[A\n",
      "Epoch 20:  96%|▉| 755/789 [30:57<01:23,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  62%|███████████████████▏           | 54/87 [02:21<00:48,  1.48s/it]\u001b[A\n",
      "Epoch 20:  96%|▉| 759/789 [31:17<01:14,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  96%|▉| 760/789 [31:21<01:11,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  97%|▉| 762/789 [31:21<01:06,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [02:45<01:10,  2.62s/it]\u001b[A\n",
      "Epoch 20:  97%|▉| 764/789 [31:21<01:01,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  97%|▉| 767/789 [31:37<00:54,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [03:01<00:25,  1.10s/it]\u001b[A\n",
      "Epoch 20:  97%|▉| 768/789 [31:42<00:52,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  98%|▉| 770/789 [31:44<00:46,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  98%|▉| 772/789 [31:44<00:41,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  98%|▉| 774/789 [31:44<00:36,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  98%|▉| 777/789 [31:57<00:29,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  85%|██████████████████████████▎    | 74/87 [03:21<00:12,  1.05it/s]\u001b[A\n",
      "Epoch 20:  99%|▉| 778/789 [32:05<00:27,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  99%|▉| 780/789 [32:10<00:22,  2.48s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  99%|▉| 781/789 [32:11<00:19,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Epoch 20:  99%|▉| 783/789 [32:11<00:14,  2.47s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  93%|████████████████████████████▊  | 81/87 [03:35<00:09,  1.64s/it]\u001b[A\n",
      "Epoch 20:  99%|▉| 785/789 [32:11<00:09,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [03:35<00:04,  1.12s/it]\u001b[A\n",
      "Epoch 20: 100%|▉| 787/789 [32:18<00:04,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [03:42<00:03,  1.92s/it]\u001b[A\n",
      "Epoch 20: 100%|█| 789/789 [32:19<00:00,  2.46s/it, loss=0.244, val_loss=0.772, a\u001b[Aclass 0: acc 0.9454545454545454, correct 52/55\n",
      "class 1: acc 0.375, correct 12/32\n",
      "Epoch 20: 100%|█| 789/789 [32:19<00:00,  2.46s/it, loss=0.244, val_loss=0.833, a\n",
      "                                                                                \u001b[AEpoch 20, step 7370: val_loss was not in top 1\n",
      "Saving latest checkpoint...\n",
      "Epoch 20: 100%|█| 789/789 [32:19<00:00,  2.46s/it, loss=0.244, val_loss=0.833, a\n"
     ]
    }
   ],
   "source": [
    "!python train.py --stage='train' --config=Camelyon/nlst.yaml  --gpus=0 --fold=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n",
      "---->Log dir: logs/Camelyon/nlst/fold4\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:37: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "test\n",
      "logs/Camelyon/nlst/fold4/epoch=10-val_loss=0.5960.ckpt\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Experiment logs directory logs/Camelyon/nlst/fold4 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Testing:  98%|█████████████████████████████████▏| 85/87 [03:44<00:02,  1.11s/it]test_Accuracy = 0.6781609058380127\n",
      "test_CohenKappa = 0.24907523393630981\n",
      "test_F1 = 0.6160151362419128\n",
      "test_Recall = 0.6147727370262146\n",
      "test_Precision = 0.6507462859153748\n",
      "auc = 0.65625\n",
      "\n",
      "class 0: acc 0.8545454545454545, correct 47/55\n",
      "class 1: acc 0.375, correct 12/32\n",
      "Testing: 100%|██████████████████████████████████| 87/87 [03:44<00:00,  2.58s/it]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python train.py --stage='test' --config='Camelyon/nlst.yaml' --gpus=0 --fold=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n",
      "---->Log dir: logs/Camelyon/nlst/fold0\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:37: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "train\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | TransMIL         | 2.7 M \n",
      "1 | loss          | CrossEntropyLoss | 0     \n",
      "2 | AUROC         | AUROC            | 0     \n",
      "3 | valid_metrics | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n",
      "10.689    Total estimated model params size (MB)\n",
      "Epoch 0:   0%|                        | 1/789 [00:00<02:55,  4.48it/s, loss=nan]/home/sci/PycharmProjects/chaofan/projects/TransMIL/MyOptimizer/radam.py:50: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "Epoch 0:  89%|██████████████████▋  | 702/789 [00:26<00:03, 26.16it/s, loss=0.66]class 0: acc 0.8506787330316742, correct 376/442\n",
      "class 1: acc 0.13076923076923078, correct 34/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  90%|██████████████████▊  | 707/789 [00:27<00:03, 26.12it/s, loss=0.66]\u001b[A\n",
      "Epoch 0:  90%|██████████████████▉  | 712/789 [00:27<00:02, 26.19it/s, loss=0.66]\u001b[A\n",
      "Epoch 0:  91%|███████████████████  | 717/789 [00:27<00:02, 26.23it/s, loss=0.66]\u001b[A\n",
      "Epoch 0:  92%|███████████████████▎ | 726/789 [00:27<00:02, 26.45it/s, loss=0.66]\u001b[A\n",
      "Epoch 0:  93%|███████████████████▌ | 735/789 [00:27<00:02, 26.65it/s, loss=0.66]\u001b[A\n",
      "Validating:  38%|███████████▊                   | 33/87 [00:00<00:00, 55.61it/s]\u001b[A\n",
      "Epoch 0:  94%|███████████████████▊ | 744/789 [00:27<00:01, 26.81it/s, loss=0.66]\u001b[A\n",
      "Epoch 0:  95%|████████████████████ | 753/789 [00:27<00:01, 27.01it/s, loss=0.66]\u001b[A\n",
      "Epoch 0:  97%|████████████████████▎| 762/789 [00:28<00:00, 27.17it/s, loss=0.66]\u001b[A\n",
      "Validating:  69%|█████████████████████▍         | 60/87 [00:01<00:00, 59.51it/s]\u001b[A\n",
      "Epoch 0:  98%|████████████████████▌| 771/789 [00:28<00:00, 27.37it/s, loss=0.66]\u001b[A\n",
      "Epoch 0:  99%|████████████████████▊| 780/789 [00:28<00:00, 27.54it/s, loss=0.66]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████| 789/789 [00:28<00:00, 27.73it/s, loss=0.66]\u001b[A/home/sci/PycharmProjects/chaofan/projects/TransMIL/utils/utils.py:67: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x_softmax = [F.softmax(x[i]) for i in range(len(x))]\n",
      "class 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 0: 100%|█| 789/789 [00:28<00:00, 27.67it/s, loss=0.66, val_loss=0.653, auc\n",
      "                                                                                \u001b[AEpoch 0, global step 350: val_loss reached 0.65313 (best 0.65313), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=00-val_loss=0.6531.ckpt\" as top 1\n",
      "Epoch 1:  89%|▉| 702/789 [00:27<00:03, 25.91it/s, loss=0.705, val_loss=0.653, auclass 0: acc 0.8823529411764706, correct 390/442\n",
      "class 1: acc 0.15, correct 39/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.76it/s]\u001b[A\n",
      "Epoch 1:  90%|▉| 711/789 [00:27<00:03, 25.87it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.02it/s]\u001b[A\n",
      "Epoch 1:  91%|▉| 720/789 [00:27<00:02, 26.02it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Epoch 1:  92%|▉| 729/789 [00:27<00:02, 26.23it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Epoch 1:  94%|▉| 738/789 [00:27<00:01, 26.40it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.33it/s]\u001b[A\n",
      "Epoch 1:  95%|▉| 747/789 [00:28<00:01, 26.55it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Epoch 1:  96%|▉| 756/789 [00:28<00:01, 26.74it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Epoch 1:  97%|▉| 765/789 [00:28<00:00, 26.93it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.10it/s]\u001b[A\n",
      "Epoch 1:  98%|▉| 774/789 [00:28<00:00, 27.11it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Epoch 1:  99%|▉| 783/789 [00:28<00:00, 27.31it/s, loss=0.705, val_loss=0.653, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.28it/s]\u001b[Aclass 0: acc 0.2, correct 11/55\n",
      "class 1: acc 0.90625, correct 29/32\n",
      "Epoch 1: 100%|█| 789/789 [00:28<00:00, 27.37it/s, loss=0.705, val_loss=0.748, au\n",
      "                                                                                \u001b[AEpoch 1, step 701: val_loss was not in top 1\n",
      "Epoch 2:  89%|▉| 702/789 [00:27<00:03, 25.85it/s, loss=0.673, val_loss=0.748, auclass 0: acc 0.8619909502262444, correct 381/442\n",
      "class 1: acc 0.16538461538461538, correct 43/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.40it/s]\u001b[A\n",
      "Epoch 2:  90%|▉| 711/789 [00:27<00:03, 25.83it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Epoch 2:  91%|▉| 720/789 [00:27<00:02, 25.97it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Validating:  21%|██████▍                        | 18/87 [00:00<00:01, 40.63it/s]\u001b[A\n",
      "Epoch 2:  92%|▉| 729/789 [00:27<00:02, 26.19it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Epoch 2:  94%|▉| 738/789 [00:27<00:01, 26.37it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Epoch 2:  95%|▉| 747/789 [00:28<00:01, 26.52it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Validating:  53%|████████████████▍              | 46/87 [00:01<00:00, 53.88it/s]\u001b[A\n",
      "Epoch 2:  96%|▉| 756/789 [00:28<00:01, 26.71it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Epoch 2:  97%|▉| 765/789 [00:28<00:00, 26.90it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Epoch 2:  98%|▉| 774/789 [00:28<00:00, 27.09it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Epoch 2:  99%|▉| 783/789 [00:28<00:00, 27.29it/s, loss=0.673, val_loss=0.748, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 67.79it/s]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 2: 100%|█| 789/789 [00:28<00:00, 27.34it/s, loss=0.673, val_loss=0.660, au\n",
      "                                                                                \u001b[AEpoch 2, step 1052: val_loss was not in top 1\n",
      "Epoch 3:  89%|▉| 702/789 [00:27<00:03, 25.80it/s, loss=0.523, val_loss=0.660, auclass 0: acc 0.8461538461538461, correct 374/442\n",
      "class 1: acc 0.23461538461538461, correct 61/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.69it/s]\u001b[A\n",
      "Epoch 3:  90%|▉| 711/789 [00:27<00:03, 25.78it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:00<00:02, 29.19it/s]\u001b[A\n",
      "Epoch 3:  91%|▉| 720/789 [00:27<00:02, 25.93it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Epoch 3:  92%|▉| 729/789 [00:27<00:02, 26.14it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Epoch 3:  94%|▉| 738/789 [00:28<00:01, 26.32it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Epoch 3:  95%|▉| 747/789 [00:28<00:01, 26.46it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Validating:  52%|████████████████               | 45/87 [00:01<00:00, 51.95it/s]\u001b[A\n",
      "Epoch 3:  96%|▉| 756/789 [00:28<00:01, 26.66it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Epoch 3:  97%|▉| 765/789 [00:28<00:00, 26.85it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Epoch 3:  98%|▉| 774/789 [00:28<00:00, 27.03it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Epoch 3:  99%|▉| 783/789 [00:28<00:00, 27.23it/s, loss=0.523, val_loss=0.660, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.93it/s]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 3: 100%|█| 789/789 [00:28<00:00, 27.29it/s, loss=0.523, val_loss=0.813, au\n",
      "                                                                                \u001b[AEpoch 3, step 1403: val_loss was not in top 1\n",
      "Epoch 4:  89%|▉| 702/789 [00:27<00:03, 25.85it/s, loss=0.652, val_loss=0.813, auclass 0: acc 0.8665158371040724, correct 383/442\n",
      "class 1: acc 0.21923076923076923, correct 57/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.74it/s]\u001b[A\n",
      "Epoch 4:  90%|▉| 711/789 [00:27<00:03, 25.85it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:00<00:02, 29.47it/s]\u001b[A\n",
      "Epoch 4:  91%|▉| 720/789 [00:27<00:02, 25.99it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Epoch 4:  92%|▉| 729/789 [00:27<00:02, 26.20it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Epoch 4:  94%|▉| 738/789 [00:27<00:01, 26.38it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Epoch 4:  95%|▉| 747/789 [00:28<00:01, 26.52it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Validating:  52%|████████████████               | 45/87 [00:01<00:00, 51.80it/s]\u001b[A\n",
      "Epoch 4:  96%|▉| 756/789 [00:28<00:01, 26.72it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Epoch 4:  97%|▉| 765/789 [00:28<00:00, 26.90it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Epoch 4:  98%|▉| 774/789 [00:28<00:00, 27.08it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Epoch 4:  99%|▉| 783/789 [00:28<00:00, 27.28it/s, loss=0.652, val_loss=0.813, au\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.59it/s]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 4: 100%|█| 789/789 [00:28<00:00, 27.34it/s, loss=0.652, val_loss=0.650, au\n",
      "                                                                                \u001b[AEpoch 4, global step 1754: val_loss reached 0.65022 (best 0.65022), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=04-val_loss=0.6502.ckpt\" as top 1\n",
      "Epoch 5:  89%|▉| 702/789 [00:27<00:03, 25.81it/s, loss=0.748, val_loss=0.650, auclass 0: acc 0.8574660633484162, correct 379/442\n",
      "class 1: acc 0.28846153846153844, correct 75/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.83it/s]\u001b[A\n",
      "Epoch 5:  90%|▉| 711/789 [00:27<00:03, 25.77it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.34it/s]\u001b[A\n",
      "Epoch 5:  91%|▉| 720/789 [00:27<00:02, 25.91it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Epoch 5:  92%|▉| 729/789 [00:27<00:02, 26.12it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Epoch 5:  94%|▉| 738/789 [00:28<00:01, 26.30it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.03it/s]\u001b[A\n",
      "Epoch 5:  95%|▉| 747/789 [00:28<00:01, 26.45it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Epoch 5:  96%|▉| 756/789 [00:28<00:01, 26.64it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Epoch 5:  97%|▉| 765/789 [00:28<00:00, 26.83it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.20it/s]\u001b[A\n",
      "Epoch 5:  98%|▉| 774/789 [00:28<00:00, 27.01it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Epoch 5:  99%|▉| 783/789 [00:28<00:00, 27.21it/s, loss=0.748, val_loss=0.650, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.27it/s]\u001b[Aclass 0: acc 0.6909090909090909, correct 38/55\n",
      "class 1: acc 0.625, correct 20/32\n",
      "Epoch 5: 100%|█| 789/789 [00:28<00:00, 27.27it/s, loss=0.748, val_loss=0.628, au\n",
      "                                                                                \u001b[AEpoch 5, global step 2105: val_loss reached 0.62804 (best 0.62804), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=05-val_loss=0.6280.ckpt\" as top 1\n",
      "Epoch 6:  89%|▉| 702/789 [00:27<00:03, 25.78it/s, loss=0.601, val_loss=0.628, auclass 0: acc 0.8597285067873304, correct 380/442\n",
      "class 1: acc 0.2846153846153846, correct 74/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.80it/s]\u001b[A\n",
      "Epoch 6:  90%|▉| 711/789 [00:27<00:03, 25.76it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 29.02it/s]\u001b[A\n",
      "Epoch 6:  91%|▉| 720/789 [00:27<00:02, 25.90it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Epoch 6:  92%|▉| 729/789 [00:27<00:02, 26.12it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Epoch 6:  94%|▉| 738/789 [00:28<00:01, 26.29it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 55.04it/s]\u001b[A\n",
      "Epoch 6:  95%|▉| 747/789 [00:28<00:01, 26.45it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Epoch 6:  96%|▉| 756/789 [00:28<00:01, 26.64it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Epoch 6:  97%|▉| 765/789 [00:28<00:00, 26.83it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Epoch 6:  98%|▉| 774/789 [00:28<00:00, 27.01it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Validating:  83%|█████████████████████████▋     | 72/87 [00:01<00:00, 61.22it/s]\u001b[A\n",
      "Epoch 6:  99%|▉| 783/789 [00:28<00:00, 27.20it/s, loss=0.601, val_loss=0.628, au\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [00:01<00:00, 64.10it/s]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.0, correct 0/32\n",
      "Epoch 6: 100%|█| 789/789 [00:28<00:00, 27.26it/s, loss=0.601, val_loss=0.724, au\n",
      "                                                                                \u001b[AEpoch 6, step 2456: val_loss was not in top 1\n",
      "Epoch 7:  89%|▉| 702/789 [00:27<00:03, 25.76it/s, loss=0.62, val_loss=0.724, aucclass 0: acc 0.8574660633484162, correct 379/442\n",
      "class 1: acc 0.26153846153846155, correct 68/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.65it/s]\u001b[A\n",
      "Epoch 7:  90%|▉| 711/789 [00:27<00:03, 25.71it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 27.21it/s]\u001b[A\n",
      "Epoch 7:  91%|▉| 720/789 [00:27<00:02, 25.85it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Epoch 7:  92%|▉| 729/789 [00:27<00:02, 26.07it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Epoch 7:  94%|▉| 738/789 [00:28<00:01, 26.24it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 53.46it/s]\u001b[A\n",
      "Epoch 7:  95%|▉| 747/789 [00:28<00:01, 26.39it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Epoch 7:  96%|▉| 756/789 [00:28<00:01, 26.58it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Epoch 7:  97%|▉| 765/789 [00:28<00:00, 26.77it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.09it/s]\u001b[A\n",
      "Epoch 7:  98%|▉| 774/789 [00:28<00:00, 26.95it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Epoch 7:  99%|▉| 783/789 [00:28<00:00, 27.15it/s, loss=0.62, val_loss=0.724, auc\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.28it/s]\u001b[Aclass 0: acc 1.0, correct 55/55\n",
      "class 1: acc 0.03125, correct 1/32\n",
      "Epoch 7: 100%|█| 789/789 [00:28<00:00, 27.21it/s, loss=0.62, val_loss=0.634, auc\n",
      "                                                                                \u001b[AEpoch 7, step 2807: val_loss was not in top 1\n",
      "Epoch 8:  89%|▉| 702/789 [00:27<00:03, 25.74it/s, loss=0.718, val_loss=0.634, auclass 0: acc 0.8891402714932126, correct 393/442\n",
      "class 1: acc 0.40384615384615385, correct 105/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.78it/s]\u001b[A\n",
      "Epoch 8:  90%|▉| 711/789 [00:27<00:03, 25.73it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 29.51it/s]\u001b[A\n",
      "Epoch 8:  91%|▉| 720/789 [00:27<00:02, 25.86it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Epoch 8:  92%|▉| 729/789 [00:27<00:02, 26.08it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Epoch 8:  94%|▉| 738/789 [00:28<00:01, 26.25it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.44it/s]\u001b[A\n",
      "Epoch 8:  95%|▉| 747/789 [00:28<00:01, 26.40it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Epoch 8:  96%|▉| 756/789 [00:28<00:01, 26.59it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Epoch 8:  97%|▉| 765/789 [00:28<00:00, 26.78it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.28it/s]\u001b[A\n",
      "Epoch 8:  98%|▉| 774/789 [00:28<00:00, 26.96it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Epoch 8:  99%|▉| 783/789 [00:28<00:00, 27.16it/s, loss=0.718, val_loss=0.634, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.01it/s]\u001b[Aclass 0: acc 0.9090909090909091, correct 50/55\n",
      "class 1: acc 0.3125, correct 10/32\n",
      "Epoch 8: 100%|█| 789/789 [00:28<00:00, 27.22it/s, loss=0.718, val_loss=0.624, au\n",
      "                                                                                \u001b[AEpoch 8, global step 3158: val_loss reached 0.62411 (best 0.62411), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=08-val_loss=0.6241.ckpt\" as top 1\n",
      "Epoch 9:  89%|▉| 702/789 [00:27<00:03, 25.74it/s, loss=0.661, val_loss=0.624, auclass 0: acc 0.8733031674208145, correct 386/442\n",
      "class 1: acc 0.39615384615384613, correct 103/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.74it/s]\u001b[A\n",
      "Epoch 9:  90%|▉| 711/789 [00:27<00:03, 25.73it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 29.67it/s]\u001b[A\n",
      "Epoch 9:  91%|▉| 720/789 [00:27<00:02, 25.87it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Epoch 9:  92%|▉| 729/789 [00:27<00:02, 26.08it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Epoch 9:  94%|▉| 738/789 [00:28<00:01, 26.26it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.95it/s]\u001b[A\n",
      "Epoch 9:  95%|▉| 747/789 [00:28<00:01, 26.41it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Epoch 9:  96%|▉| 756/789 [00:28<00:01, 26.60it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Epoch 9:  97%|▉| 765/789 [00:28<00:00, 26.79it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.79it/s]\u001b[A\n",
      "Epoch 9:  98%|▉| 774/789 [00:28<00:00, 26.97it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Epoch 9:  99%|▉| 783/789 [00:28<00:00, 27.17it/s, loss=0.661, val_loss=0.624, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.03it/s]\u001b[Aclass 0: acc 0.7454545454545455, correct 41/55\n",
      "class 1: acc 0.65625, correct 21/32\n",
      "Epoch 9: 100%|█| 789/789 [00:28<00:00, 27.23it/s, loss=0.661, val_loss=0.600, au\n",
      "                                                                                \u001b[AEpoch 9, global step 3509: val_loss reached 0.60010 (best 0.60010), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=09-val_loss=0.6001.ckpt\" as top 1\n",
      "Epoch 10:  89%|▉| 702/789 [00:27<00:03, 25.85it/s, loss=0.509, val_loss=0.600, aclass 0: acc 0.8936651583710408, correct 395/442\n",
      "class 1: acc 0.41923076923076924, correct 109/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.42it/s]\u001b[A\n",
      "Epoch 10:  90%|▉| 711/789 [00:27<00:03, 25.80it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 27.66it/s]\u001b[A\n",
      "Epoch 10:  91%|▉| 720/789 [00:27<00:02, 25.94it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Epoch 10:  92%|▉| 729/789 [00:27<00:02, 26.16it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Epoch 10:  94%|▉| 738/789 [00:28<00:01, 26.33it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 53.53it/s]\u001b[A\n",
      "Epoch 10:  95%|▉| 747/789 [00:28<00:01, 26.47it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Epoch 10:  96%|▉| 756/789 [00:28<00:01, 26.66it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Epoch 10:  97%|▉| 765/789 [00:28<00:00, 26.85it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 59.47it/s]\u001b[A\n",
      "Epoch 10:  98%|▉| 774/789 [00:28<00:00, 27.03it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Epoch 10:  99%|▉| 783/789 [00:28<00:00, 27.23it/s, loss=0.509, val_loss=0.600, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 63.15it/s]\u001b[Aclass 0: acc 0.9090909090909091, correct 50/55\n",
      "class 1: acc 0.46875, correct 15/32\n",
      "Epoch 10: 100%|█| 789/789 [00:28<00:00, 27.28it/s, loss=0.509, val_loss=0.615, a\n",
      "                                                                                \u001b[AEpoch 10, step 3860: val_loss was not in top 1\n",
      "Epoch 11:  89%|▉| 702/789 [00:27<00:03, 25.83it/s, loss=0.485, val_loss=0.615, aclass 0: acc 0.9027149321266968, correct 399/442\n",
      "class 1: acc 0.45, correct 117/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.65it/s]\u001b[A\n",
      "Epoch 11:  90%|▉| 711/789 [00:27<00:03, 25.83it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Epoch 11:  91%|▉| 720/789 [00:27<00:02, 25.97it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Validating:  21%|██████▍                        | 18/87 [00:00<00:01, 41.03it/s]\u001b[A\n",
      "Epoch 11:  92%|▉| 729/789 [00:27<00:02, 26.18it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Epoch 11:  94%|▉| 738/789 [00:27<00:01, 26.36it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Epoch 11:  95%|▉| 747/789 [00:28<00:01, 26.51it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Validating:  53%|████████████████▍              | 46/87 [00:01<00:00, 53.85it/s]\u001b[A\n",
      "Epoch 11:  96%|▉| 756/789 [00:28<00:01, 26.71it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Epoch 11:  97%|▉| 765/789 [00:28<00:00, 26.90it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Epoch 11:  98%|▉| 774/789 [00:28<00:00, 27.08it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Epoch 11:  99%|▉| 783/789 [00:28<00:00, 27.28it/s, loss=0.485, val_loss=0.615, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 67.19it/s]\u001b[Aclass 0: acc 0.8181818181818182, correct 45/55\n",
      "class 1: acc 0.59375, correct 19/32\n",
      "Epoch 11: 100%|█| 789/789 [00:28<00:00, 27.34it/s, loss=0.485, val_loss=0.562, a\n",
      "                                                                                \u001b[AEpoch 11, global step 4211: val_loss reached 0.56152 (best 0.56152), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=11-val_loss=0.5615.ckpt\" as top 1\n",
      "Epoch 12:  89%|▉| 702/789 [00:27<00:03, 25.78it/s, loss=0.589, val_loss=0.562, aclass 0: acc 0.9276018099547512, correct 410/442\n",
      "class 1: acc 0.46153846153846156, correct 120/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.75it/s]\u001b[A\n",
      "Epoch 12:  90%|▉| 711/789 [00:27<00:03, 25.77it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Epoch 12:  91%|▉| 720/789 [00:27<00:02, 25.92it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Validating:  21%|██████▍                        | 18/87 [00:00<00:01, 40.65it/s]\u001b[A\n",
      "Epoch 12:  92%|▉| 729/789 [00:27<00:02, 26.13it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Epoch 12:  94%|▉| 738/789 [00:28<00:01, 26.31it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Epoch 12:  95%|▉| 747/789 [00:28<00:01, 26.46it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Validating:  52%|████████████████               | 45/87 [00:01<00:00, 52.23it/s]\u001b[A\n",
      "Epoch 12:  96%|▉| 756/789 [00:28<00:01, 26.65it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Epoch 12:  97%|▉| 765/789 [00:28<00:00, 26.84it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Epoch 12:  98%|▉| 774/789 [00:28<00:00, 27.02it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Epoch 12:  99%|▉| 783/789 [00:28<00:00, 27.22it/s, loss=0.589, val_loss=0.562, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.99it/s]\u001b[Aclass 0: acc 0.8545454545454545, correct 47/55\n",
      "class 1: acc 0.53125, correct 17/32\n",
      "Epoch 12: 100%|█| 789/789 [00:28<00:00, 27.28it/s, loss=0.589, val_loss=0.576, a\n",
      "                                                                                \u001b[AEpoch 12, step 4562: val_loss was not in top 1\n",
      "Epoch 13:  89%|▉| 702/789 [00:27<00:03, 25.79it/s, loss=0.505, val_loss=0.576, aclass 0: acc 0.9140271493212669, correct 404/442\n",
      "class 1: acc 0.5153846153846153, correct 134/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.52it/s]\u001b[A\n",
      "Epoch 13:  90%|▉| 711/789 [00:27<00:03, 25.76it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.76it/s]\u001b[A\n",
      "Epoch 13:  91%|▉| 720/789 [00:27<00:02, 25.90it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Epoch 13:  92%|▉| 729/789 [00:27<00:02, 26.12it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Epoch 13:  94%|▉| 738/789 [00:28<00:01, 26.29it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.40it/s]\u001b[A\n",
      "Epoch 13:  95%|▉| 747/789 [00:28<00:01, 26.44it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Epoch 13:  96%|▉| 756/789 [00:28<00:01, 26.63it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Epoch 13:  97%|▉| 765/789 [00:28<00:00, 26.82it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.13it/s]\u001b[A\n",
      "Epoch 13:  98%|▉| 774/789 [00:28<00:00, 27.00it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Epoch 13:  99%|▉| 783/789 [00:28<00:00, 27.20it/s, loss=0.505, val_loss=0.576, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.52it/s]\u001b[Aclass 0: acc 0.7636363636363637, correct 42/55\n",
      "class 1: acc 0.78125, correct 25/32\n",
      "Epoch 13: 100%|█| 789/789 [00:28<00:00, 27.26it/s, loss=0.505, val_loss=0.542, a\n",
      "                                                                                \u001b[AEpoch 13, global step 4913: val_loss reached 0.54242 (best 0.54242), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=13-val_loss=0.5424.ckpt\" as top 1\n",
      "Epoch 14:  89%|▉| 702/789 [00:27<00:03, 25.79it/s, loss=0.751, val_loss=0.542, aclass 0: acc 0.9524886877828054, correct 421/442\n",
      "class 1: acc 0.5269230769230769, correct 137/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.68it/s]\u001b[A\n",
      "Epoch 14:  90%|▉| 711/789 [00:27<00:03, 25.77it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 29.17it/s]\u001b[A\n",
      "Epoch 14:  91%|▉| 720/789 [00:27<00:02, 25.92it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Epoch 14:  92%|▉| 729/789 [00:27<00:02, 26.14it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Epoch 14:  94%|▉| 738/789 [00:28<00:01, 26.31it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 55.16it/s]\u001b[A\n",
      "Epoch 14:  95%|▉| 747/789 [00:28<00:01, 26.46it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Epoch 14:  96%|▉| 756/789 [00:28<00:01, 26.66it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Epoch 14:  97%|▉| 765/789 [00:28<00:00, 26.85it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 61.13it/s]\u001b[A\n",
      "Epoch 14:  98%|▉| 774/789 [00:28<00:00, 27.03it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Epoch 14:  99%|▉| 783/789 [00:28<00:00, 27.22it/s, loss=0.751, val_loss=0.542, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.45it/s]\u001b[Aclass 0: acc 0.9272727272727272, correct 51/55\n",
      "class 1: acc 0.40625, correct 13/32\n",
      "Epoch 14: 100%|█| 789/789 [00:28<00:00, 27.28it/s, loss=0.751, val_loss=0.549, a\n",
      "                                                                                \u001b[AEpoch 14, step 5264: val_loss was not in top 1\n",
      "Epoch 15:  89%|▉| 702/789 [00:27<00:03, 25.63it/s, loss=0.549, val_loss=0.549, aclass 0: acc 0.9343891402714932, correct 413/442\n",
      "class 1: acc 0.5038461538461538, correct 131/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.62it/s]\u001b[A\n",
      "Epoch 15:  90%|▉| 711/789 [00:27<00:03, 25.60it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.39it/s]\u001b[A\n",
      "Epoch 15:  91%|▉| 720/789 [00:27<00:02, 25.74it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Epoch 15:  92%|▉| 729/789 [00:28<00:02, 25.96it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Epoch 15:  94%|▉| 738/789 [00:28<00:01, 26.13it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.53it/s]\u001b[A\n",
      "Epoch 15:  95%|▉| 747/789 [00:28<00:01, 26.28it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Epoch 15:  96%|▉| 756/789 [00:28<00:01, 26.47it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Epoch 15:  97%|▉| 765/789 [00:28<00:00, 26.66it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.42it/s]\u001b[A\n",
      "Epoch 15:  98%|▉| 774/789 [00:28<00:00, 26.84it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Epoch 15:  99%|▉| 783/789 [00:28<00:00, 27.04it/s, loss=0.549, val_loss=0.549, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 63.18it/s]\u001b[Aclass 0: acc 0.5818181818181818, correct 32/55\n",
      "class 1: acc 0.875, correct 28/32\n",
      "Epoch 15: 100%|█| 789/789 [00:29<00:00, 27.09it/s, loss=0.549, val_loss=0.772, a\n",
      "                                                                                \u001b[AEpoch 15, step 5615: val_loss was not in top 1\n",
      "Epoch 16:  89%|▉| 702/789 [00:27<00:03, 25.73it/s, loss=0.372, val_loss=0.772, aclass 0: acc 0.9027149321266968, correct 399/442\n",
      "class 1: acc 0.6, correct 156/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.66it/s]\u001b[A\n",
      "Epoch 16:  90%|▉| 711/789 [00:27<00:03, 25.73it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:00<00:02, 29.35it/s]\u001b[A\n",
      "Epoch 16:  91%|▉| 720/789 [00:27<00:02, 25.86it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Epoch 16:  92%|▉| 729/789 [00:27<00:02, 26.08it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Epoch 16:  94%|▉| 738/789 [00:28<00:01, 26.26it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Epoch 16:  95%|▉| 747/789 [00:28<00:01, 26.41it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Validating:  53%|████████████████▍              | 46/87 [00:01<00:00, 53.98it/s]\u001b[A\n",
      "Epoch 16:  96%|▉| 756/789 [00:28<00:01, 26.60it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Epoch 16:  97%|▉| 765/789 [00:28<00:00, 26.79it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Epoch 16:  98%|▉| 774/789 [00:28<00:00, 26.97it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Epoch 16:  99%|▉| 783/789 [00:28<00:00, 27.17it/s, loss=0.372, val_loss=0.772, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.73it/s]\u001b[Aclass 0: acc 0.8909090909090909, correct 49/55\n",
      "class 1: acc 0.59375, correct 19/32\n",
      "Epoch 16: 100%|█| 789/789 [00:28<00:00, 27.22it/s, loss=0.372, val_loss=0.484, a\n",
      "                                                                                \u001b[AEpoch 16, global step 5966: val_loss reached 0.48389 (best 0.48389), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=16-val_loss=0.4839.ckpt\" as top 1\n",
      "Epoch 17:  89%|▉| 702/789 [00:27<00:03, 25.76it/s, loss=0.765, val_loss=0.484, aclass 0: acc 0.920814479638009, correct 407/442\n",
      "class 1: acc 0.5961538461538461, correct 155/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.72it/s]\u001b[A\n",
      "Epoch 17:  90%|▉| 711/789 [00:27<00:03, 25.73it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.88it/s]\u001b[A\n",
      "Epoch 17:  91%|▉| 720/789 [00:27<00:02, 25.87it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Epoch 17:  92%|▉| 729/789 [00:27<00:02, 26.09it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Epoch 17:  94%|▉| 738/789 [00:28<00:01, 26.26it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.75it/s]\u001b[A\n",
      "Epoch 17:  95%|▉| 747/789 [00:28<00:01, 26.41it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Epoch 17:  96%|▉| 756/789 [00:28<00:01, 26.61it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Epoch 17:  97%|▉| 765/789 [00:28<00:00, 26.79it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.60it/s]\u001b[A\n",
      "Epoch 17:  98%|▉| 774/789 [00:28<00:00, 26.98it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Epoch 17:  99%|▉| 783/789 [00:28<00:00, 27.17it/s, loss=0.765, val_loss=0.484, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 63.93it/s]\u001b[Aclass 0: acc 0.8181818181818182, correct 45/55\n",
      "class 1: acc 0.6875, correct 22/32\n",
      "Epoch 17: 100%|█| 789/789 [00:28<00:00, 27.23it/s, loss=0.765, val_loss=0.527, a\n",
      "                                                                                \u001b[AEpoch 17, step 6317: val_loss was not in top 1\n",
      "Epoch 18:  89%|▉| 702/789 [00:27<00:03, 25.74it/s, loss=0.36, val_loss=0.527, auclass 0: acc 0.9253393665158371, correct 409/442\n",
      "class 1: acc 0.6115384615384616, correct 159/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.58it/s]\u001b[A\n",
      "Epoch 18:  90%|▉| 711/789 [00:27<00:03, 25.72it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 29.66it/s]\u001b[A\n",
      "Epoch 18:  91%|▉| 720/789 [00:27<00:02, 25.86it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Epoch 18:  92%|▉| 729/789 [00:27<00:02, 26.08it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Epoch 18:  94%|▉| 738/789 [00:28<00:01, 26.25it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.71it/s]\u001b[A\n",
      "Epoch 18:  95%|▉| 747/789 [00:28<00:01, 26.40it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Epoch 18:  96%|▉| 756/789 [00:28<00:01, 26.59it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Epoch 18:  97%|▉| 765/789 [00:28<00:00, 26.78it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 59.98it/s]\u001b[A\n",
      "Epoch 18:  98%|▉| 774/789 [00:28<00:00, 26.96it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Epoch 18:  99%|▉| 783/789 [00:28<00:00, 27.16it/s, loss=0.36, val_loss=0.527, au\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.06it/s]\u001b[Aclass 0: acc 0.8727272727272727, correct 48/55\n",
      "class 1: acc 0.5625, correct 18/32\n",
      "Epoch 18: 100%|█| 789/789 [00:28<00:00, 27.22it/s, loss=0.36, val_loss=0.508, au\n",
      "                                                                                \u001b[AEpoch 18, step 6668: val_loss was not in top 1\n",
      "Epoch 19:  89%|▉| 702/789 [00:27<00:03, 25.69it/s, loss=0.438, val_loss=0.508, aclass 0: acc 0.8981900452488688, correct 397/442\n",
      "class 1: acc 0.6807692307692308, correct 177/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.57it/s]\u001b[A\n",
      "Epoch 19:  90%|▉| 711/789 [00:27<00:03, 25.68it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:00<00:02, 29.18it/s]\u001b[A\n",
      "Epoch 19:  91%|▉| 720/789 [00:27<00:02, 25.82it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Epoch 19:  92%|▉| 729/789 [00:27<00:02, 26.04it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Epoch 19:  94%|▉| 738/789 [00:28<00:01, 26.21it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Epoch 19:  95%|▉| 747/789 [00:28<00:01, 26.36it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Validating:  53%|████████████████▍              | 46/87 [00:01<00:00, 53.29it/s]\u001b[A\n",
      "Epoch 19:  96%|▉| 756/789 [00:28<00:01, 26.55it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Epoch 19:  97%|▉| 765/789 [00:28<00:00, 26.74it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Epoch 19:  98%|▉| 774/789 [00:28<00:00, 26.92it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Epoch 19:  99%|▉| 783/789 [00:28<00:00, 27.12it/s, loss=0.438, val_loss=0.508, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.68it/s]\u001b[Aclass 0: acc 0.7818181818181819, correct 43/55\n",
      "class 1: acc 0.6875, correct 22/32\n",
      "Epoch 19: 100%|█| 789/789 [00:29<00:00, 27.18it/s, loss=0.438, val_loss=0.536, a\n",
      "                                                                                \u001b[AEpoch 19, step 7019: val_loss was not in top 1\n",
      "Epoch 20:  89%|▉| 702/789 [00:27<00:03, 25.70it/s, loss=0.331, val_loss=0.536, aclass 0: acc 0.9366515837104072, correct 414/442\n",
      "class 1: acc 0.6961538461538461, correct 181/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:16,  5.28it/s]\u001b[A\n",
      "Epoch 20:  90%|▉| 711/789 [00:27<00:03, 25.69it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:00<00:02, 29.51it/s]\u001b[A\n",
      "Epoch 20:  91%|▉| 720/789 [00:27<00:02, 25.83it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Epoch 20:  92%|▉| 729/789 [00:27<00:02, 26.05it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Epoch 20:  94%|▉| 738/789 [00:28<00:01, 26.22it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Epoch 20:  95%|▉| 747/789 [00:28<00:01, 26.37it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Validating:  52%|████████████████               | 45/87 [00:01<00:00, 52.05it/s]\u001b[A\n",
      "Epoch 20:  96%|▉| 756/789 [00:28<00:01, 26.56it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Epoch 20:  97%|▉| 765/789 [00:28<00:00, 26.75it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Epoch 20:  98%|▉| 774/789 [00:28<00:00, 26.93it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Epoch 20:  99%|▉| 783/789 [00:28<00:00, 27.13it/s, loss=0.331, val_loss=0.536, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.92it/s]\u001b[Aclass 0: acc 0.7636363636363637, correct 42/55\n",
      "class 1: acc 0.8125, correct 26/32\n",
      "Epoch 20: 100%|█| 789/789 [00:29<00:00, 27.19it/s, loss=0.331, val_loss=0.522, a\n",
      "                                                                                \u001b[AEpoch 20, step 7370: val_loss was not in top 1\n",
      "Epoch 21:  89%|▉| 702/789 [00:27<00:03, 25.69it/s, loss=0.199, val_loss=0.522, aclass 0: acc 0.9343891402714932, correct 413/442\n",
      "class 1: acc 0.75, correct 195/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:16,  5.27it/s]\u001b[A\n",
      "Epoch 21:  90%|▉| 711/789 [00:27<00:03, 25.68it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Epoch 21:  91%|▉| 720/789 [00:27<00:02, 25.83it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Validating:  21%|██████▍                        | 18/87 [00:00<00:01, 41.15it/s]\u001b[A\n",
      "Epoch 21:  92%|▉| 729/789 [00:27<00:02, 26.04it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Epoch 21:  94%|▉| 738/789 [00:28<00:01, 26.22it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Epoch 21:  95%|▉| 747/789 [00:28<00:01, 26.36it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Validating:  52%|████████████████               | 45/87 [00:01<00:00, 52.22it/s]\u001b[A\n",
      "Epoch 21:  96%|▉| 756/789 [00:28<00:01, 26.56it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Epoch 21:  97%|▉| 765/789 [00:28<00:00, 26.75it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Epoch 21:  98%|▉| 774/789 [00:28<00:00, 26.93it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Epoch 21:  99%|▉| 783/789 [00:28<00:00, 27.12it/s, loss=0.199, val_loss=0.522, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.86it/s]\u001b[Aclass 0: acc 0.8727272727272727, correct 48/55\n",
      "class 1: acc 0.625, correct 20/32\n",
      "Epoch 21: 100%|█| 789/789 [00:29<00:00, 27.19it/s, loss=0.199, val_loss=0.501, a\n",
      "                                                                                \u001b[AEpoch 21, step 7721: val_loss was not in top 1\n",
      "Epoch 22:  89%|▉| 702/789 [00:27<00:03, 25.67it/s, loss=0.443, val_loss=0.501, aclass 0: acc 0.9004524886877828, correct 398/442\n",
      "class 1: acc 0.7653846153846153, correct 199/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:14,  5.78it/s]\u001b[A\n",
      "Epoch 22:  90%|▉| 711/789 [00:27<00:03, 25.67it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Validating:  13%|███▉                           | 11/87 [00:00<00:02, 30.07it/s]\u001b[A\n",
      "Epoch 22:  91%|▉| 720/789 [00:27<00:02, 25.82it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Epoch 22:  92%|▉| 729/789 [00:28<00:02, 26.00it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Epoch 22:  94%|▉| 738/789 [00:28<00:01, 26.18it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 53.57it/s]\u001b[A\n",
      "Epoch 22:  95%|▉| 747/789 [00:28<00:01, 26.33it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Epoch 22:  96%|▉| 756/789 [00:28<00:01, 26.52it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Epoch 22:  97%|▉| 765/789 [00:28<00:00, 26.71it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.08it/s]\u001b[A\n",
      "Epoch 22:  98%|▉| 774/789 [00:28<00:00, 26.89it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Epoch 22:  99%|▉| 783/789 [00:28<00:00, 27.08it/s, loss=0.443, val_loss=0.501, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.10it/s]\u001b[Aclass 0: acc 0.8909090909090909, correct 49/55\n",
      "class 1: acc 0.53125, correct 17/32\n",
      "Epoch 22: 100%|█| 789/789 [00:29<00:00, 27.14it/s, loss=0.443, val_loss=0.446, a\n",
      "                                                                                \u001b[AEpoch 22, global step 8072: val_loss reached 0.44647 (best 0.44647), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/nlst/fold0/epoch=22-val_loss=0.4465.ckpt\" as top 1\n",
      "Epoch 23:  89%|▉| 702/789 [00:27<00:03, 25.69it/s, loss=0.364, val_loss=0.446, aclass 0: acc 0.9366515837104072, correct 414/442\n",
      "class 1: acc 0.7961538461538461, correct 207/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.50it/s]\u001b[A\n",
      "Epoch 23:  90%|▉| 711/789 [00:27<00:03, 25.68it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Epoch 23:  91%|▉| 720/789 [00:27<00:02, 25.82it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Validating:  21%|██████▍                        | 18/87 [00:00<00:01, 40.45it/s]\u001b[A\n",
      "Epoch 23:  92%|▉| 729/789 [00:27<00:02, 26.04it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Epoch 23:  94%|▉| 738/789 [00:28<00:01, 26.21it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Epoch 23:  95%|▉| 747/789 [00:28<00:01, 26.36it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Validating:  52%|████████████████               | 45/87 [00:01<00:00, 51.90it/s]\u001b[A\n",
      "Epoch 23:  96%|▉| 756/789 [00:28<00:01, 26.56it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Epoch 23:  97%|▉| 765/789 [00:28<00:00, 26.74it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Epoch 23:  98%|▉| 774/789 [00:28<00:00, 26.92it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Epoch 23:  99%|▉| 783/789 [00:28<00:00, 27.12it/s, loss=0.364, val_loss=0.446, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.80it/s]\u001b[Aclass 0: acc 0.8363636363636363, correct 46/55\n",
      "class 1: acc 0.625, correct 20/32\n",
      "Epoch 23: 100%|█| 789/789 [00:29<00:00, 27.17it/s, loss=0.364, val_loss=0.474, a\n",
      "                                                                                \u001b[AEpoch 23, step 8423: val_loss was not in top 1\n",
      "Epoch 24:  89%|▉| 702/789 [00:27<00:03, 25.65it/s, loss=0.371, val_loss=0.474, aclass 0: acc 0.9321266968325792, correct 412/442\n",
      "class 1: acc 0.8076923076923077, correct 210/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.59it/s]\u001b[A\n",
      "Epoch 24:  90%|▉| 711/789 [00:27<00:03, 25.62it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.09it/s]\u001b[A\n",
      "Epoch 24:  91%|▉| 720/789 [00:27<00:02, 25.76it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Epoch 24:  92%|▉| 729/789 [00:28<00:02, 25.97it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Epoch 24:  94%|▉| 738/789 [00:28<00:01, 26.14it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 53.99it/s]\u001b[A\n",
      "Epoch 24:  95%|▉| 747/789 [00:28<00:01, 26.29it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Epoch 24:  96%|▉| 756/789 [00:28<00:01, 26.49it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Epoch 24:  97%|▉| 765/789 [00:28<00:00, 26.67it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.20it/s]\u001b[A\n",
      "Epoch 24:  98%|▉| 774/789 [00:28<00:00, 26.85it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Epoch 24:  99%|▉| 783/789 [00:28<00:00, 27.05it/s, loss=0.371, val_loss=0.474, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 63.91it/s]\u001b[Aclass 0: acc 0.8, correct 44/55\n",
      "class 1: acc 0.71875, correct 23/32\n",
      "Epoch 24: 100%|█| 789/789 [00:29<00:00, 27.11it/s, loss=0.371, val_loss=0.656, a\n",
      "                                                                                \u001b[AEpoch 24, step 8774: val_loss was not in top 1\n",
      "Epoch 25:  89%|▉| 702/789 [00:27<00:03, 25.66it/s, loss=0.415, val_loss=0.656, aclass 0: acc 0.9276018099547512, correct 410/442\n",
      "class 1: acc 0.7961538461538461, correct 207/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.58it/s]\u001b[A\n",
      "Epoch 25:  90%|▉| 711/789 [00:27<00:03, 25.64it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.91it/s]\u001b[A\n",
      "Epoch 25:  91%|▉| 720/789 [00:27<00:02, 25.78it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Epoch 25:  92%|▉| 729/789 [00:28<00:02, 25.99it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Epoch 25:  94%|▉| 738/789 [00:28<00:01, 26.16it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.62it/s]\u001b[A\n",
      "Epoch 25:  95%|▉| 747/789 [00:28<00:01, 26.32it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Epoch 25:  96%|▉| 756/789 [00:28<00:01, 26.51it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Epoch 25:  97%|▉| 765/789 [00:28<00:00, 26.70it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.37it/s]\u001b[A\n",
      "Epoch 25:  98%|▉| 774/789 [00:28<00:00, 26.88it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Epoch 25:  99%|▉| 783/789 [00:28<00:00, 27.07it/s, loss=0.415, val_loss=0.656, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 64.23it/s]\u001b[Aclass 0: acc 0.8363636363636363, correct 46/55\n",
      "class 1: acc 0.65625, correct 21/32\n",
      "Epoch 25: 100%|█| 789/789 [00:29<00:00, 27.14it/s, loss=0.415, val_loss=0.622, a\n",
      "                                                                                \u001b[AEpoch 25, step 9125: val_loss was not in top 1\n",
      "Epoch 26:  89%|▉| 702/789 [00:27<00:03, 25.74it/s, loss=0.456, val_loss=0.622, aclass 0: acc 0.9366515837104072, correct 414/442\n",
      "class 1: acc 0.7961538461538461, correct 207/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:17,  4.84it/s]\u001b[A\n",
      "Epoch 26:  90%|▉| 711/789 [00:27<00:03, 25.68it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 26.85it/s]\u001b[A\n",
      "Epoch 26:  91%|▉| 720/789 [00:27<00:02, 25.83it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Epoch 26:  92%|▉| 729/789 [00:27<00:02, 26.05it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Epoch 26:  94%|▉| 738/789 [00:28<00:01, 26.22it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 54.90it/s]\u001b[A\n",
      "Epoch 26:  95%|▉| 747/789 [00:28<00:01, 26.37it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Epoch 26:  96%|▉| 756/789 [00:28<00:01, 26.57it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Epoch 26:  97%|▉| 765/789 [00:28<00:00, 26.76it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Epoch 26:  98%|▉| 774/789 [00:28<00:00, 26.94it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Validating:  83%|█████████████████████████▋     | 72/87 [00:01<00:00, 61.50it/s]\u001b[A\n",
      "Epoch 26:  99%|▉| 783/789 [00:28<00:00, 27.13it/s, loss=0.456, val_loss=0.622, a\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 87/87 [00:01<00:00, 63.99it/s]\u001b[Aclass 0: acc 0.9090909090909091, correct 50/55\n",
      "class 1: acc 0.5625, correct 18/32\n",
      "Epoch 26: 100%|█| 789/789 [00:29<00:00, 27.19it/s, loss=0.456, val_loss=0.555, a\n",
      "                                                                                \u001b[AEpoch 26, step 9476: val_loss was not in top 1\n",
      "Epoch 27:  89%|▉| 702/789 [00:27<00:03, 25.82it/s, loss=0.312, val_loss=0.555, aclass 0: acc 0.9615384615384616, correct 425/442\n",
      "class 1: acc 0.8346153846153846, correct 217/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:16,  5.27it/s]\u001b[A\n",
      "Epoch 27:  90%|▉| 711/789 [00:27<00:03, 25.80it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Epoch 27:  91%|▉| 720/789 [00:27<00:02, 25.95it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Validating:  21%|██████▍                        | 18/87 [00:00<00:01, 41.08it/s]\u001b[A\n",
      "Epoch 27:  92%|▉| 729/789 [00:27<00:02, 26.17it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Epoch 27:  94%|▉| 738/789 [00:28<00:01, 26.34it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Epoch 27:  95%|▉| 747/789 [00:28<00:01, 26.49it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Validating:  52%|████████████████               | 45/87 [00:01<00:00, 52.56it/s]\u001b[A\n",
      "Epoch 27:  96%|▉| 756/789 [00:28<00:01, 26.69it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Epoch 27:  97%|▉| 765/789 [00:28<00:00, 26.88it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Epoch 27:  98%|▉| 774/789 [00:28<00:00, 27.06it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Epoch 27:  99%|▉| 783/789 [00:28<00:00, 27.26it/s, loss=0.312, val_loss=0.555, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 67.27it/s]\u001b[Aclass 0: acc 0.6181818181818182, correct 34/55\n",
      "class 1: acc 0.875, correct 28/32\n",
      "Epoch 27: 100%|█| 789/789 [00:28<00:00, 27.31it/s, loss=0.312, val_loss=0.932, a\n",
      "                                                                                \u001b[AEpoch 27, step 9827: val_loss was not in top 1\n",
      "Epoch 28:  89%|▉| 702/789 [00:27<00:03, 25.81it/s, loss=0.164, val_loss=0.932, aclass 0: acc 0.9343891402714932, correct 413/442\n",
      "class 1: acc 0.8615384615384616, correct 224/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.46it/s]\u001b[A\n",
      "Epoch 28:  90%|▉| 711/789 [00:27<00:03, 25.80it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Epoch 28:  91%|▉| 720/789 [00:27<00:02, 25.94it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Validating:  21%|██████▍                        | 18/87 [00:00<00:01, 40.99it/s]\u001b[A\n",
      "Epoch 28:  92%|▉| 729/789 [00:27<00:02, 26.16it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Epoch 28:  94%|▉| 738/789 [00:28<00:01, 26.33it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Epoch 28:  95%|▉| 747/789 [00:28<00:01, 26.47it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Validating:  53%|████████████████▍              | 46/87 [00:01<00:00, 52.19it/s]\u001b[A\n",
      "Epoch 28:  96%|▉| 756/789 [00:28<00:01, 26.67it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Epoch 28:  97%|▉| 765/789 [00:28<00:00, 26.86it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Epoch 28:  98%|▉| 774/789 [00:28<00:00, 27.04it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Epoch 28:  99%|▉| 783/789 [00:28<00:00, 27.24it/s, loss=0.164, val_loss=0.932, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 66.68it/s]\u001b[Aclass 0: acc 0.7818181818181819, correct 43/55\n",
      "class 1: acc 0.75, correct 24/32\n",
      "Epoch 28: 100%|█| 789/789 [00:28<00:00, 27.30it/s, loss=0.164, val_loss=0.648, a\n",
      "                                                                                \u001b[AEpoch 28, step 10178: val_loss was not in top 1\n",
      "Epoch 29:  89%|▉| 702/789 [00:27<00:03, 25.80it/s, loss=0.191, val_loss=0.648, aclass 0: acc 0.9570135746606335, correct 423/442\n",
      "class 1: acc 0.8769230769230769, correct 228/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.43it/s]\u001b[A\n",
      "Epoch 29:  90%|▉| 711/789 [00:27<00:03, 25.76it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 27.94it/s]\u001b[A\n",
      "Epoch 29:  91%|▉| 720/789 [00:27<00:02, 25.91it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Epoch 29:  92%|▉| 729/789 [00:27<00:02, 26.13it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Epoch 29:  94%|▉| 738/789 [00:28<00:01, 26.30it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 55.02it/s]\u001b[A\n",
      "Epoch 29:  95%|▉| 747/789 [00:28<00:01, 26.45it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Epoch 29:  96%|▉| 756/789 [00:28<00:01, 26.64it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Epoch 29:  97%|▉| 765/789 [00:28<00:00, 26.83it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 60.25it/s]\u001b[A\n",
      "Epoch 29:  98%|▉| 774/789 [00:28<00:00, 27.01it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Epoch 29:  99%|▉| 783/789 [00:28<00:00, 27.21it/s, loss=0.191, val_loss=0.648, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 85/87 [00:01<00:00, 63.87it/s]\u001b[Aclass 0: acc 0.7454545454545455, correct 41/55\n",
      "class 1: acc 0.78125, correct 25/32\n",
      "Epoch 29: 100%|█| 789/789 [00:28<00:00, 27.26it/s, loss=0.191, val_loss=1.000, a\n",
      "                                                                                \u001b[AEpoch 29, step 10529: val_loss was not in top 1\n",
      "Epoch 30:  89%|▉| 702/789 [00:27<00:03, 25.70it/s, loss=0.266, val_loss=1.000, aclass 0: acc 0.9502262443438914, correct 420/442\n",
      "class 1: acc 0.8461538461538461, correct 220/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:18,  4.63it/s]\u001b[A\n",
      "Epoch 30:  90%|▉| 711/789 [00:27<00:03, 25.66it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Epoch 30:  91%|▉| 720/789 [00:27<00:02, 25.81it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Epoch 30:  92%|▉| 729/789 [00:28<00:02, 26.03it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Validating:  31%|█████████▌                     | 27/87 [00:00<00:01, 53.99it/s]\u001b[A\n",
      "Epoch 30:  94%|▉| 738/789 [00:28<00:01, 26.21it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Epoch 30:  95%|▉| 747/789 [00:28<00:01, 26.36it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Validating:  54%|████████████████▋              | 47/87 [00:01<00:00, 56.10it/s]\u001b[A\n",
      "Epoch 30:  96%|▉| 756/789 [00:28<00:01, 26.55it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Epoch 30:  97%|▉| 765/789 [00:28<00:00, 26.75it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Epoch 30:  98%|▉| 774/789 [00:28<00:00, 26.93it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Epoch 30:  99%|▉| 783/789 [00:28<00:00, 27.13it/s, loss=0.266, val_loss=1.000, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 68.50it/s]\u001b[Aclass 0: acc 0.9454545454545454, correct 52/55\n",
      "class 1: acc 0.4375, correct 14/32\n",
      "Epoch 30: 100%|█| 789/789 [00:29<00:00, 27.20it/s, loss=0.266, val_loss=0.608, a\n",
      "                                                                                \u001b[AEpoch 30, step 10880: val_loss was not in top 1\n",
      "Epoch 31:  89%|▉| 702/789 [00:27<00:03, 25.83it/s, loss=0.118, val_loss=0.608, aclass 0: acc 0.9751131221719457, correct 431/442\n",
      "class 1: acc 0.8961538461538462, correct 233/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:15,  5.64it/s]\u001b[A\n",
      "Epoch 31:  90%|▉| 711/789 [00:27<00:03, 25.81it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Validating:  11%|███▌                           | 10/87 [00:00<00:02, 28.94it/s]\u001b[A\n",
      "Epoch 31:  91%|▉| 720/789 [00:27<00:02, 25.95it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Epoch 31:  92%|▉| 729/789 [00:27<00:02, 26.17it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Epoch 31:  94%|▉| 738/789 [00:28<00:01, 26.34it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Validating:  43%|█████████████▏                 | 37/87 [00:00<00:00, 55.63it/s]\u001b[A\n",
      "Epoch 31:  95%|▉| 747/789 [00:28<00:01, 26.50it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Epoch 31:  96%|▉| 756/789 [00:28<00:01, 26.70it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Epoch 31:  97%|▉| 765/789 [00:28<00:00, 26.89it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Validating:  74%|██████████████████████▊        | 64/87 [00:01<00:00, 61.72it/s]\u001b[A\n",
      "Epoch 31:  98%|▉| 774/789 [00:28<00:00, 27.07it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Epoch 31:  99%|▉| 783/789 [00:28<00:00, 27.27it/s, loss=0.118, val_loss=0.608, a\u001b[A\n",
      "Validating:  99%|██████████████████████████████▋| 86/87 [00:01<00:00, 63.84it/s]\u001b[Aclass 0: acc 0.8545454545454545, correct 47/55\n",
      "class 1: acc 0.6875, correct 22/32\n",
      "Epoch 31: 100%|█| 789/789 [00:28<00:00, 27.33it/s, loss=0.118, val_loss=0.701, a\n",
      "                                                                                \u001b[AEpoch 31, step 11231: val_loss was not in top 1\n",
      "Epoch 32:  89%|▉| 702/789 [00:27<00:03, 25.99it/s, loss=0.253, val_loss=0.701, aclass 0: acc 0.9479638009049773, correct 419/442\n",
      "class 1: acc 0.9115384615384615, correct 237/260\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/87 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/87 [00:00<00:17,  4.92it/s]\u001b[A\n",
      "Epoch 32:  90%|▉| 711/789 [00:27<00:03, 25.96it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Epoch 32:  91%|▉| 720/789 [00:27<00:02, 26.11it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Epoch 32:  92%|▉| 729/789 [00:27<00:02, 26.33it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Validating:  31%|█████████▌                     | 27/87 [00:00<00:01, 53.96it/s]\u001b[A\n",
      "Epoch 32:  94%|▉| 738/789 [00:27<00:01, 26.51it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Epoch 32:  95%|▉| 747/789 [00:28<00:01, 26.66it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Validating:  54%|████████████████▋              | 47/87 [00:01<00:00, 56.28it/s]\u001b[A\n",
      "Epoch 32:  96%|▉| 756/789 [00:28<00:01, 26.86it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Epoch 32:  97%|▉| 765/789 [00:28<00:00, 27.05it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Epoch 32:  98%|▉| 774/789 [00:28<00:00, 27.24it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Epoch 32:  99%|▉| 783/789 [00:28<00:00, 27.44it/s, loss=0.253, val_loss=0.701, a\u001b[A\n",
      "Validating:  95%|█████████████████████████████▌ | 83/87 [00:01<00:00, 68.80it/s]\u001b[Aclass 0: acc 0.8363636363636363, correct 46/55\n",
      "class 1: acc 0.75, correct 24/32\n",
      "Epoch 32: 100%|█| 789/789 [00:28<00:00, 27.50it/s, loss=0.253, val_loss=0.619, a\n",
      "                                                                                \u001b[AEpoch 32, step 11582: val_loss was not in top 1\n",
      "Saving latest checkpoint...\n",
      "Epoch 32: 100%|█| 789/789 [00:28<00:00, 27.46it/s, loss=0.253, val_loss=0.619, a\n"
     ]
    }
   ],
   "source": [
    "!python train.py --stage='train' --config=Camelyon/nlst.yaml  --gpus=0 --fold=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n",
      "---->Log dir: logs/Camelyon/nlst/fold0\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:37: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "test\n",
      "logs/Camelyon/nlst/fold0/epoch=22-val_loss=0.4465.ckpt\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Experiment logs directory logs/Camelyon/nlst/fold0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Testing: 100%|██████████████████████████████████| 87/87 [00:01<00:00, 73.27it/s]test_Accuracy = 0.7126436829566956\n",
      "test_CohenKappa = 0.3149605989456177\n",
      "test_F1 = 0.644897997379303\n",
      "test_Recall = 0.6420454978942871\n",
      "test_Precision = 0.710084080696106\n",
      "auc = 0.7284090518951416\n",
      "\n",
      "class 0: acc 0.9090909090909091, correct 50/55\n",
      "class 1: acc 0.375, correct 12/32\n",
      "Testing: 100%|██████████████████████████████████| 87/87 [00:01<00:00, 61.32it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python train.py --stage='test' --config='Camelyon/nlst.yaml' --gpus=0 --fold=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCGA-NSCLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n",
      "---->Log dir: logs/Camelyon/tcga_nsclc/fold4\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:37: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "train\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | TransMIL         | 2.7 M \n",
      "1 | loss          | CrossEntropyLoss | 0     \n",
      "2 | AUROC         | AUROC            | 0     \n",
      "3 | valid_metrics | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n",
      "10.689    Total estimated model params size (MB)\n",
      "Epoch 0:   0%|                        | 1/743 [00:00<03:25,  3.60it/s, loss=nan]/home/sci/PycharmProjects/chaofan/projects/TransMIL/MyOptimizer/radam.py:50: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "Epoch 0:  87%|█████████████████▍  | 650/743 [00:23<00:03, 27.90it/s, loss=0.545]class 0: acc 0.48514851485148514, correct 147/303\n",
      "class 1: acc 0.7089337175792507, correct 246/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  88%|█████████████████▌  | 652/743 [00:23<00:03, 27.62it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  89%|█████████████████▊  | 660/743 [00:23<00:02, 27.84it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  90%|█████████████████▉  | 668/743 [00:23<00:02, 28.04it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  91%|██████████████████▏ | 676/743 [00:23<00:02, 28.23it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  92%|██████████████████▍ | 685/743 [00:24<00:02, 28.47it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  93%|██████████████████▋ | 694/743 [00:24<00:01, 28.71it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  95%|██████████████████▉ | 703/743 [00:24<00:01, 28.95it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  96%|███████████████████▏| 712/743 [00:24<00:01, 29.16it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  97%|███████████████████▍| 721/743 [00:24<00:00, 29.38it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  98%|███████████████████▋| 730/743 [00:24<00:00, 29.59it/s, loss=0.545]\u001b[A\n",
      "Epoch 0:  99%|███████████████████▉| 739/743 [00:24<00:00, 29.81it/s, loss=0.545]\u001b[A\n",
      "Validating:  96%|█████████████████████████████▋ | 89/93 [00:01<00:00, 73.23it/s]\u001b[A/home/sci/PycharmProjects/chaofan/projects/TransMIL/utils/utils.py:67: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x_softmax = [F.softmax(x[i]) for i in range(len(x))]\n",
      "class 0: acc 0.06382978723404255, correct 3/47\n",
      "class 1: acc 1.0, correct 46/46\n",
      "Epoch 0: 100%|█| 743/743 [00:24<00:00, 29.83it/s, loss=0.545, val_loss=0.640, au\n",
      "                                                                                \u001b[AEpoch 0, global step 324: val_loss reached 0.64031 (best 0.64031), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/tcga_nsclc/fold4/epoch=00-val_loss=0.6403.ckpt\" as top 1\n",
      "Epoch 1:  87%|▊| 650/743 [00:25<00:03, 25.64it/s, loss=0.58, val_loss=0.640, aucclass 0: acc 0.6105610561056105, correct 185/303\n",
      "class 1: acc 0.7262247838616714, correct 252/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  88%|▉| 657/743 [00:25<00:03, 25.49it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Epoch 1:  90%|▉| 666/743 [00:25<00:02, 25.72it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Validating:  17%|█████▎                         | 16/93 [00:00<00:01, 39.24it/s]\u001b[A\n",
      "Epoch 1:  91%|▉| 675/743 [00:26<00:02, 25.93it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Epoch 1:  92%|▉| 685/743 [00:26<00:02, 26.20it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Epoch 1:  94%|▉| 695/743 [00:26<00:01, 26.46it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Epoch 1:  95%|▉| 705/743 [00:26<00:01, 26.71it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Epoch 1:  96%|▉| 715/743 [00:26<00:01, 26.94it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Validating:  70%|█████████████████████▋         | 65/93 [00:01<00:00, 67.38it/s]\u001b[A\n",
      "Epoch 1:  98%|▉| 725/743 [00:26<00:00, 27.17it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Epoch 1:  99%|▉| 735/743 [00:26<00:00, 27.43it/s, loss=0.58, val_loss=0.640, auc\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 91/93 [00:01<00:00, 73.63it/s]\u001b[Aclass 0: acc 0.8723404255319149, correct 41/47\n",
      "class 1: acc 0.9347826086956522, correct 43/46\n",
      "Epoch 1: 100%|█| 743/743 [00:26<00:00, 27.53it/s, loss=0.58, val_loss=0.369, auc\n",
      "                                                                                \u001b[AEpoch 1, global step 649: val_loss reached 0.36923 (best 0.36923), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/tcga_nsclc/fold4/epoch=01-val_loss=0.3692.ckpt\" as top 1\n",
      "Epoch 2:  87%|▊| 650/743 [00:30<00:04, 21.02it/s, loss=0.533, val_loss=0.369, auclass 0: acc 0.7656765676567657, correct 232/303\n",
      "class 1: acc 0.8097982708933718, correct 281/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:29,  3.14it/s]\u001b[A\n",
      "Epoch 2:  89%|▉| 660/743 [00:31<00:03, 21.04it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Epoch 2:  90%|▉| 670/743 [00:31<00:03, 21.27it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Epoch 2:  92%|▉| 680/743 [00:31<00:02, 21.49it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Epoch 2:  93%|▉| 690/743 [00:31<00:02, 21.72it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.30it/s]\u001b[A\n",
      "Epoch 2:  94%|▉| 700/743 [00:31<00:01, 21.95it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Epoch 2:  96%|▉| 710/743 [00:32<00:01, 22.16it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Epoch 2:  97%|▉| 720/743 [00:32<00:01, 22.38it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Epoch 2:  98%|▉| 730/743 [00:32<00:00, 22.59it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Epoch 2: 100%|▉| 740/743 [00:32<00:00, 22.81it/s, loss=0.533, val_loss=0.369, au\u001b[A\n",
      "Validating:  97%|██████████████████████████████ | 90/93 [00:01<00:00, 73.94it/s]\u001b[Aclass 0: acc 0.9787234042553191, correct 46/47\n",
      "class 1: acc 0.7608695652173914, correct 35/46\n",
      "Epoch 2: 100%|█| 743/743 [00:32<00:00, 22.83it/s, loss=0.533, val_loss=0.343, au\n",
      "                                                                                \u001b[AEpoch 2, global step 974: val_loss reached 0.34290 (best 0.34290), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/tcga_nsclc/fold4/epoch=02-val_loss=0.3429.ckpt\" as top 1\n",
      "Epoch 3:  87%|▊| 650/743 [00:23<00:03, 27.80it/s, loss=0.322, val_loss=0.343, auclass 0: acc 0.7722772277227723, correct 234/303\n",
      "class 1: acc 0.8386167146974063, correct 291/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:27,  3.39it/s]\u001b[A\n",
      "Epoch 3:  89%|▉| 660/743 [00:23<00:02, 27.73it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Epoch 3:  90%|▉| 670/743 [00:23<00:02, 27.98it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Epoch 3:  92%|▉| 680/743 [00:24<00:02, 28.24it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Epoch 3:  93%|▉| 690/743 [00:24<00:01, 28.50it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.43it/s]\u001b[A\n",
      "Epoch 3:  94%|▉| 700/743 [00:24<00:01, 28.77it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Epoch 3:  96%|▉| 710/743 [00:24<00:01, 28.99it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Epoch 3:  97%|▉| 720/743 [00:24<00:00, 29.24it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Epoch 3:  98%|▉| 730/743 [00:24<00:00, 29.47it/s, loss=0.322, val_loss=0.343, au\u001b[A\n",
      "Validating:  87%|███████████████████████████    | 81/93 [00:01<00:00, 71.99it/s]\u001b[A\n",
      "Epoch 3: 100%|▉| 740/743 [00:24<00:00, 29.72it/s, loss=0.322, val_loss=0.343, au\u001b[Aclass 0: acc 0.7446808510638298, correct 35/47\n",
      "class 1: acc 0.9782608695652174, correct 45/46\n",
      "Epoch 3: 100%|█| 743/743 [00:25<00:00, 29.72it/s, loss=0.322, val_loss=0.342, au\n",
      "                                                                                \u001b[AEpoch 3, global step 1299: val_loss reached 0.34222 (best 0.34222), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/tcga_nsclc/fold4/epoch=03-val_loss=0.3422.ckpt\" as top 1\n",
      "Epoch 4:  87%|▊| 650/743 [00:23<00:03, 27.59it/s, loss=0.589, val_loss=0.342, auclass 0: acc 0.7953795379537953, correct 241/303\n",
      "class 1: acc 0.8414985590778098, correct 292/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:26,  3.44it/s]\u001b[A\n",
      "Epoch 4:  89%|▉| 660/743 [00:23<00:03, 27.54it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Epoch 4:  90%|▉| 670/743 [00:24<00:02, 27.79it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Epoch 4:  92%|▉| 680/743 [00:24<00:02, 28.05it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Epoch 4:  93%|▉| 690/743 [00:24<00:01, 28.30it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.11it/s]\u001b[A\n",
      "Epoch 4:  94%|▉| 700/743 [00:24<00:01, 28.57it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Epoch 4:  96%|▉| 710/743 [00:24<00:01, 28.79it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Epoch 4:  97%|▉| 720/743 [00:24<00:00, 29.05it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Epoch 4:  98%|▉| 730/743 [00:24<00:00, 29.29it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Epoch 4: 100%|▉| 740/743 [00:25<00:00, 29.54it/s, loss=0.589, val_loss=0.342, au\u001b[A\n",
      "Validating:  97%|██████████████████████████████ | 90/93 [00:01<00:00, 73.64it/s]\u001b[Aclass 0: acc 0.8723404255319149, correct 41/47\n",
      "class 1: acc 0.8260869565217391, correct 38/46\n",
      "Epoch 4: 100%|█| 743/743 [00:25<00:00, 29.53it/s, loss=0.589, val_loss=0.316, au\n",
      "                                                                                \u001b[AEpoch 4, global step 1624: val_loss reached 0.31577 (best 0.31577), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/tcga_nsclc/fold4/epoch=04-val_loss=0.3158.ckpt\" as top 1\n",
      "Epoch 5:  87%|▊| 650/743 [00:23<00:03, 27.62it/s, loss=0.207, val_loss=0.316, auclass 0: acc 0.8646864686468647, correct 262/303\n",
      "class 1: acc 0.8501440922190202, correct 295/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:28,  3.26it/s]\u001b[A\n",
      "Epoch 5:  89%|▉| 660/743 [00:23<00:03, 27.54it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Epoch 5:  90%|▉| 670/743 [00:24<00:02, 27.79it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Epoch 5:  92%|▉| 680/743 [00:24<00:02, 28.05it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Epoch 5:  93%|▉| 690/743 [00:24<00:01, 28.31it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.98it/s]\u001b[A\n",
      "Epoch 5:  94%|▉| 700/743 [00:24<00:01, 28.59it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Epoch 5:  96%|▉| 710/743 [00:24<00:01, 28.81it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Epoch 5:  97%|▉| 720/743 [00:24<00:00, 29.07it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Epoch 5:  98%|▉| 730/743 [00:24<00:00, 29.30it/s, loss=0.207, val_loss=0.316, au\u001b[A\n",
      "Validating:  87%|███████████████████████████    | 81/93 [00:01<00:00, 73.90it/s]\u001b[A\n",
      "Epoch 5: 100%|▉| 740/743 [00:25<00:00, 29.55it/s, loss=0.207, val_loss=0.316, au\u001b[Aclass 0: acc 0.7872340425531915, correct 37/47\n",
      "class 1: acc 0.8913043478260869, correct 41/46\n",
      "Epoch 5: 100%|█| 743/743 [00:25<00:00, 29.55it/s, loss=0.207, val_loss=0.332, au\n",
      "                                                                                \u001b[AEpoch 5, step 1949: val_loss was not in top 1\n",
      "Epoch 6:  87%|▊| 650/743 [00:23<00:03, 27.60it/s, loss=0.329, val_loss=0.332, auclass 0: acc 0.8679867986798679, correct 263/303\n",
      "class 1: acc 0.8501440922190202, correct 295/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:27,  3.33it/s]\u001b[A\n",
      "Epoch 6:  89%|▉| 660/743 [00:23<00:03, 27.52it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Epoch 6:  90%|▉| 670/743 [00:24<00:02, 27.78it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Epoch 6:  92%|▉| 680/743 [00:24<00:02, 28.04it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Validating:  33%|██████████▎                    | 31/93 [00:00<00:01, 59.79it/s]\u001b[A\n",
      "Epoch 6:  93%|▉| 690/743 [00:24<00:01, 28.30it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Epoch 6:  94%|▉| 700/743 [00:24<00:01, 28.58it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Epoch 6:  96%|▉| 710/743 [00:24<00:01, 28.80it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Epoch 6:  97%|▉| 720/743 [00:24<00:00, 29.05it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Epoch 6:  98%|▉| 730/743 [00:24<00:00, 29.29it/s, loss=0.329, val_loss=0.332, au\u001b[A\n",
      "Validating:  86%|██████████████████████████▋    | 80/93 [00:01<00:00, 72.80it/s]\u001b[A\n",
      "Epoch 6: 100%|▉| 740/743 [00:25<00:00, 29.54it/s, loss=0.329, val_loss=0.332, au\u001b[Aclass 0: acc 0.8936170212765957, correct 42/47\n",
      "class 1: acc 0.9130434782608695, correct 42/46\n",
      "Epoch 6: 100%|█| 743/743 [00:25<00:00, 29.54it/s, loss=0.329, val_loss=0.297, au\n",
      "                                                                                \u001b[AEpoch 6, global step 2274: val_loss reached 0.29713 (best 0.29713), saving model to \"/home/sci/PycharmProjects/chaofan/projects/TransMIL/logs/Camelyon/tcga_nsclc/fold4/epoch=06-val_loss=0.2971.ckpt\" as top 1\n",
      "Epoch 7:  87%|▊| 650/743 [00:23<00:03, 27.77it/s, loss=0.259, val_loss=0.297, auclass 0: acc 0.8514851485148515, correct 258/303\n",
      "class 1: acc 0.8876080691642652, correct 308/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:27,  3.39it/s]\u001b[A\n",
      "Epoch 7:  89%|▉| 660/743 [00:23<00:03, 27.66it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Epoch 7:  90%|▉| 670/743 [00:24<00:02, 27.92it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Epoch 7:  92%|▉| 680/743 [00:24<00:02, 28.17it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Validating:  32%|██████████                     | 30/93 [00:00<00:01, 57.66it/s]\u001b[A\n",
      "Epoch 7:  93%|▉| 690/743 [00:24<00:01, 28.43it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Epoch 7:  94%|▉| 700/743 [00:24<00:01, 28.70it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Epoch 7:  96%|▉| 710/743 [00:24<00:01, 28.92it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Epoch 7:  97%|▉| 720/743 [00:24<00:00, 29.17it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Validating:  76%|███████████████████████▋       | 71/93 [00:01<00:00, 69.28it/s]\u001b[A\n",
      "Epoch 7:  98%|▉| 730/743 [00:24<00:00, 29.40it/s, loss=0.259, val_loss=0.297, au\u001b[A\n",
      "Epoch 7: 100%|▉| 740/743 [00:24<00:00, 29.66it/s, loss=0.259, val_loss=0.297, au\u001b[Aclass 0: acc 0.9787234042553191, correct 46/47\n",
      "class 1: acc 0.6304347826086957, correct 29/46\n",
      "Epoch 7: 100%|█| 743/743 [00:25<00:00, 29.65it/s, loss=0.259, val_loss=0.510, au\n",
      "                                                                                \u001b[AEpoch 7, step 2599: val_loss was not in top 1\n",
      "Epoch 8:  87%|▊| 650/743 [00:23<00:03, 27.60it/s, loss=0.352, val_loss=0.510, auclass 0: acc 0.8745874587458746, correct 265/303\n",
      "class 1: acc 0.8818443804034583, correct 306/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:26,  3.53it/s]\u001b[A\n",
      "Epoch 8:  89%|▉| 660/743 [00:23<00:03, 27.55it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Epoch 8:  90%|▉| 670/743 [00:24<00:02, 27.80it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Epoch 8:  92%|▉| 680/743 [00:24<00:02, 28.06it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Epoch 8:  93%|▉| 690/743 [00:24<00:01, 28.32it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.95it/s]\u001b[A\n",
      "Epoch 8:  94%|▉| 700/743 [00:24<00:01, 28.59it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Epoch 8:  96%|▉| 710/743 [00:24<00:01, 28.81it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Epoch 8:  97%|▉| 720/743 [00:24<00:00, 29.06it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Epoch 8:  98%|▉| 730/743 [00:24<00:00, 29.30it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Epoch 8: 100%|▉| 740/743 [00:25<00:00, 29.55it/s, loss=0.352, val_loss=0.510, au\u001b[A\n",
      "Validating:  97%|██████████████████████████████ | 90/93 [00:01<00:00, 73.28it/s]\u001b[Aclass 0: acc 0.9574468085106383, correct 45/47\n",
      "class 1: acc 0.6956521739130435, correct 32/46\n",
      "Epoch 8: 100%|█| 743/743 [00:25<00:00, 29.54it/s, loss=0.352, val_loss=0.353, au\n",
      "                                                                                \u001b[AEpoch 8, step 2924: val_loss was not in top 1\n",
      "Epoch 9:  87%|▊| 650/743 [00:23<00:03, 27.54it/s, loss=0.186, val_loss=0.353, auclass 0: acc 0.8745874587458746, correct 265/303\n",
      "class 1: acc 0.8933717579250721, correct 310/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:28,  3.22it/s]\u001b[A\n",
      "Epoch 9:  89%|▉| 660/743 [00:24<00:03, 27.46it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Epoch 9:  90%|▉| 670/743 [00:24<00:02, 27.72it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Epoch 9:  92%|▉| 680/743 [00:24<00:02, 27.97it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Epoch 9:  93%|▉| 690/743 [00:24<00:01, 28.23it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.90it/s]\u001b[A\n",
      "Epoch 9:  94%|▉| 700/743 [00:24<00:01, 28.51it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Epoch 9:  96%|▉| 710/743 [00:24<00:01, 28.73it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Epoch 9:  97%|▉| 720/743 [00:24<00:00, 28.98it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Epoch 9:  98%|▉| 730/743 [00:24<00:00, 29.22it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Epoch 9: 100%|▉| 740/743 [00:25<00:00, 29.47it/s, loss=0.186, val_loss=0.353, au\u001b[A\n",
      "Validating:  99%|██████████████████████████████▋| 92/93 [00:01<00:00, 73.64it/s]\u001b[Aclass 0: acc 0.9148936170212766, correct 43/47\n",
      "class 1: acc 0.7608695652173914, correct 35/46\n",
      "Epoch 9: 100%|█| 743/743 [00:25<00:00, 29.45it/s, loss=0.186, val_loss=0.408, au\n",
      "                                                                                \u001b[AEpoch 9, step 3249: val_loss was not in top 1\n",
      "Epoch 10:  87%|▊| 650/743 [00:23<00:03, 27.74it/s, loss=0.272, val_loss=0.408, aclass 0: acc 0.9306930693069307, correct 282/303\n",
      "class 1: acc 0.9221902017291066, correct 320/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:26,  3.50it/s]\u001b[A\n",
      "Epoch 10:  89%|▉| 660/743 [00:23<00:02, 27.68it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Epoch 10:  90%|▉| 670/743 [00:23<00:02, 27.94it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Epoch 10:  92%|▉| 680/743 [00:24<00:02, 28.19it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Epoch 10:  93%|▉| 690/743 [00:24<00:01, 28.45it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 65.01it/s]\u001b[A\n",
      "Epoch 10:  94%|▉| 700/743 [00:24<00:01, 28.73it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Epoch 10:  96%|▉| 710/743 [00:24<00:01, 28.94it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Epoch 10:  97%|▉| 720/743 [00:24<00:00, 29.20it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Epoch 10:  98%|▉| 730/743 [00:24<00:00, 29.43it/s, loss=0.272, val_loss=0.408, a\u001b[A\n",
      "Validating:  87%|███████████████████████████    | 81/93 [00:01<00:00, 72.90it/s]\u001b[A\n",
      "Epoch 10: 100%|▉| 740/743 [00:24<00:00, 29.68it/s, loss=0.272, val_loss=0.408, a\u001b[Aclass 0: acc 0.425531914893617, correct 20/47\n",
      "class 1: acc 1.0, correct 46/46\n",
      "Epoch 10: 100%|█| 743/743 [00:25<00:00, 29.66it/s, loss=0.272, val_loss=0.933, a\n",
      "                                                                                \u001b[AEpoch 10, step 3574: val_loss was not in top 1\n",
      "Epoch 11:  87%|▊| 650/743 [00:23<00:03, 27.52it/s, loss=0.175, val_loss=0.933, aclass 0: acc 0.900990099009901, correct 273/303\n",
      "class 1: acc 0.9193083573487032, correct 319/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:28,  3.25it/s]\u001b[A\n",
      "Epoch 11:  89%|▉| 660/743 [00:24<00:03, 27.45it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Epoch 11:  90%|▉| 670/743 [00:24<00:02, 27.70it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Epoch 11:  92%|▉| 680/743 [00:24<00:02, 27.96it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Epoch 11:  93%|▉| 690/743 [00:24<00:01, 28.22it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.90it/s]\u001b[A\n",
      "Epoch 11:  94%|▉| 700/743 [00:24<00:01, 28.50it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Epoch 11:  96%|▉| 710/743 [00:24<00:01, 28.72it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Epoch 11:  97%|▉| 720/743 [00:24<00:00, 28.97it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Epoch 11:  98%|▉| 730/743 [00:24<00:00, 29.21it/s, loss=0.175, val_loss=0.933, a\u001b[A\n",
      "Validating:  87%|███████████████████████████    | 81/93 [00:01<00:00, 73.48it/s]\u001b[A\n",
      "Epoch 11: 100%|▉| 740/743 [00:25<00:00, 29.45it/s, loss=0.175, val_loss=0.933, a\u001b[Aclass 0: acc 0.7446808510638298, correct 35/47\n",
      "class 1: acc 0.9130434782608695, correct 42/46\n",
      "Epoch 11: 100%|█| 743/743 [00:25<00:00, 29.45it/s, loss=0.175, val_loss=0.411, a\n",
      "                                                                                \u001b[AEpoch 11, step 3899: val_loss was not in top 1\n",
      "Epoch 12:  87%|▊| 650/743 [00:23<00:03, 27.61it/s, loss=0.173, val_loss=0.411, aclass 0: acc 0.9042904290429042, correct 274/303\n",
      "class 1: acc 0.9135446685878963, correct 317/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:26,  3.41it/s]\u001b[A\n",
      "Epoch 12:  89%|▉| 660/743 [00:23<00:03, 27.54it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Epoch 12:  90%|▉| 670/743 [00:24<00:02, 27.80it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Epoch 12:  92%|▉| 680/743 [00:24<00:02, 28.06it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Epoch 12:  93%|▉| 690/743 [00:24<00:01, 28.32it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 65.41it/s]\u001b[A\n",
      "Epoch 12:  94%|▉| 700/743 [00:24<00:01, 28.59it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Epoch 12:  96%|▉| 710/743 [00:24<00:01, 28.81it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Epoch 12:  97%|▉| 720/743 [00:24<00:00, 29.07it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Epoch 12:  98%|▉| 730/743 [00:24<00:00, 29.31it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Epoch 12: 100%|▉| 740/743 [00:25<00:00, 29.56it/s, loss=0.173, val_loss=0.411, a\u001b[A\n",
      "Validating:  97%|██████████████████████████████ | 90/93 [00:01<00:00, 74.00it/s]\u001b[Aclass 0: acc 0.851063829787234, correct 40/47\n",
      "class 1: acc 0.8478260869565217, correct 39/46\n",
      "Epoch 12: 100%|█| 743/743 [00:25<00:00, 29.56it/s, loss=0.173, val_loss=0.321, a\n",
      "                                                                                \u001b[AEpoch 12, step 4224: val_loss was not in top 1\n",
      "Epoch 13:  87%|▊| 650/743 [00:23<00:03, 27.63it/s, loss=0.272, val_loss=0.321, aclass 0: acc 0.9438943894389439, correct 286/303\n",
      "class 1: acc 0.9077809798270894, correct 315/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:26,  3.44it/s]\u001b[A\n",
      "Epoch 13:  89%|▉| 660/743 [00:23<00:03, 27.57it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Epoch 13:  90%|▉| 670/743 [00:24<00:02, 27.82it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Epoch 13:  92%|▉| 680/743 [00:24<00:02, 28.08it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Epoch 13:  93%|▉| 690/743 [00:24<00:01, 28.34it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 65.31it/s]\u001b[A\n",
      "Epoch 13:  94%|▉| 700/743 [00:24<00:01, 28.61it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Epoch 13:  96%|▉| 710/743 [00:24<00:01, 28.83it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Epoch 13:  97%|▉| 720/743 [00:24<00:00, 29.09it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Epoch 13:  98%|▉| 730/743 [00:24<00:00, 29.33it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Epoch 13: 100%|▉| 740/743 [00:25<00:00, 29.58it/s, loss=0.272, val_loss=0.321, a\u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 91/93 [00:01<00:00, 73.96it/s]\u001b[Aclass 0: acc 0.8936170212765957, correct 42/47\n",
      "class 1: acc 0.8478260869565217, correct 39/46\n",
      "Epoch 13: 100%|█| 743/743 [00:25<00:00, 29.57it/s, loss=0.272, val_loss=0.302, a\n",
      "                                                                                \u001b[AEpoch 13, step 4549: val_loss was not in top 1\n",
      "Epoch 14:  87%|▊| 650/743 [00:23<00:03, 27.51it/s, loss=0.0677, val_loss=0.302, class 0: acc 0.9372937293729373, correct 284/303\n",
      "class 1: acc 0.9337175792507204, correct 324/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:27,  3.40it/s]\u001b[A\n",
      "Epoch 14:  89%|▉| 660/743 [00:24<00:03, 27.45it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Epoch 14:  90%|▉| 670/743 [00:24<00:02, 27.70it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Epoch 14:  92%|▉| 680/743 [00:24<00:02, 27.96it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Epoch 14:  93%|▉| 690/743 [00:24<00:01, 28.22it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 65.22it/s]\u001b[A\n",
      "Epoch 14:  94%|▉| 700/743 [00:24<00:01, 28.49it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Epoch 14:  96%|▉| 710/743 [00:24<00:01, 28.71it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Epoch 14:  97%|▉| 720/743 [00:24<00:00, 28.96it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Epoch 14:  98%|▉| 730/743 [00:24<00:00, 29.20it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Epoch 14: 100%|▉| 740/743 [00:25<00:00, 29.45it/s, loss=0.0677, val_loss=0.302, \u001b[A\n",
      "Validating:  98%|██████████████████████████████▎| 91/93 [00:01<00:00, 73.66it/s]\u001b[Aclass 0: acc 0.7021276595744681, correct 33/47\n",
      "class 1: acc 0.9347826086956522, correct 43/46\n",
      "Epoch 14: 100%|█| 743/743 [00:25<00:00, 29.45it/s, loss=0.0677, val_loss=0.643, \n",
      "                                                                                \u001b[AEpoch 14, step 4874: val_loss was not in top 1\n",
      "Epoch 15:  87%|▊| 650/743 [00:23<00:03, 27.66it/s, loss=0.275, val_loss=0.643, aclass 0: acc 0.9306930693069307, correct 282/303\n",
      "class 1: acc 0.9221902017291066, correct 320/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:26,  3.46it/s]\u001b[A\n",
      "Epoch 15:  89%|▉| 660/743 [00:23<00:03, 27.59it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Epoch 15:  90%|▉| 670/743 [00:24<00:02, 27.85it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Epoch 15:  92%|▉| 680/743 [00:24<00:02, 28.10it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Epoch 15:  93%|▉| 690/743 [00:24<00:01, 28.36it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Validating:  43%|█████████████▎                 | 40/93 [00:00<00:00, 64.85it/s]\u001b[A\n",
      "Epoch 15:  94%|▉| 700/743 [00:24<00:01, 28.63it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Epoch 15:  96%|▉| 710/743 [00:24<00:01, 28.85it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Epoch 15:  97%|▉| 720/743 [00:24<00:00, 29.10it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Epoch 15:  98%|▉| 730/743 [00:24<00:00, 29.33it/s, loss=0.275, val_loss=0.643, a\u001b[A\n",
      "Validating:  87%|███████████████████████████    | 81/93 [00:01<00:00, 72.23it/s]\u001b[A\n",
      "Epoch 15: 100%|▉| 740/743 [00:25<00:00, 29.58it/s, loss=0.275, val_loss=0.643, a\u001b[Aclass 0: acc 0.8085106382978723, correct 38/47\n",
      "class 1: acc 0.9130434782608695, correct 42/46\n",
      "Epoch 15: 100%|█| 743/743 [00:25<00:00, 29.58it/s, loss=0.275, val_loss=0.391, a\n",
      "                                                                                \u001b[AEpoch 15, step 5199: val_loss was not in top 1\n",
      "Epoch 16:  87%|▊| 650/743 [00:23<00:03, 27.68it/s, loss=0.126, val_loss=0.391, aclass 0: acc 0.9372937293729373, correct 284/303\n",
      "class 1: acc 0.9250720461095101, correct 321/347\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                               | 1/93 [00:00<00:26,  3.51it/s]\u001b[A\n",
      "Epoch 16:  89%|▉| 660/743 [00:23<00:03, 27.63it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Epoch 16:  90%|▉| 670/743 [00:24<00:02, 27.88it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Epoch 16:  92%|▉| 680/743 [00:24<00:02, 28.10it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Validating:  33%|██████████▎                    | 31/93 [00:00<00:01, 55.54it/s]\u001b[A\n",
      "Epoch 16:  93%|▉| 690/743 [00:24<00:01, 28.35it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Epoch 16:  94%|▉| 700/743 [00:24<00:01, 28.63it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Epoch 16:  96%|▉| 710/743 [00:24<00:01, 28.85it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Epoch 16:  97%|▉| 720/743 [00:24<00:00, 29.10it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Epoch 16:  98%|▉| 730/743 [00:24<00:00, 29.34it/s, loss=0.126, val_loss=0.391, a\u001b[A\n",
      "Validating:  86%|██████████████████████████▋    | 80/93 [00:01<00:00, 71.32it/s]\u001b[A\n",
      "Epoch 16: 100%|▉| 740/743 [00:25<00:00, 29.59it/s, loss=0.126, val_loss=0.391, a\u001b[Aclass 0: acc 0.7021276595744681, correct 33/47\n",
      "class 1: acc 0.9565217391304348, correct 44/46\n",
      "Epoch 16: 100%|█| 743/743 [00:25<00:00, 29.57it/s, loss=0.126, val_loss=0.498, a\n",
      "                                                                                \u001b[AEpoch 16, step 5524: val_loss was not in top 1\n",
      "Saving latest checkpoint...\n",
      "Epoch 16: 100%|█| 743/743 [00:25<00:00, 29.53it/s, loss=0.126, val_loss=0.498, a\n"
     ]
    }
   ],
   "source": [
    "!python train.py --stage='train' --config=Camelyon/tcga_nsclc.yaml  --gpus=0 --fold=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n",
      "---->Log dir: logs/Camelyon/tcga_nsclc/fold1\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:37: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "test\n",
      "logs/Camelyon/tcga_nsclc/fold1/epoch=03-val_loss=0.2792.ckpt\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Experiment logs directory logs/Camelyon/tcga_nsclc/fold1 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Testing:  90%|██████████████████████████████▋   | 66/73 [00:01<00:00, 69.80it/s]test_Accuracy = 0.8219178318977356\n",
      "test_CohenKappa = 0.6470807194709778\n",
      "test_F1 = 0.8219177722930908\n",
      "test_Recall = 0.8295454978942871\n",
      "test_Precision = 0.8295454978942871\n",
      "auc = 0.8810606002807617\n",
      "\n",
      "class 0: acc 0.9090909090909091, correct 30/33\n",
      "class 1: acc 0.75, correct 30/40\n",
      "Testing: 100%|██████████████████████████████████| 73/73 [00:01<00:00, 52.81it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "logs/Camelyon/tcga_nsclc/fold1/epoch=18-val_loss=0.2335.ckpt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 93, in <module>\n",
      "    main(cfg)\n",
      "  File \"train.py\", line 79, in main\n",
      "    trainer.test(model=new_model, datamodule=dm)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 923, in test\n",
      "    results = self.__test_given_model(model, test_dataloaders)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 981, in __test_given_model\n",
      "    results = self.fit(model)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 475, in fit\n",
      "    self.setup_trainer(model)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 423, in setup_trainer\n",
      "    self.logger.save()\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py\", line 388, in save\n",
      "    logger.save()\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py\", line 40, in wrapped_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/loggers/csv_logs.py\", line 197, in save\n",
      "    self.experiment.save()\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/loggers/csv_logs.py\", line 85, in save\n",
      "    save_hparams_to_yaml(hparams_file, self.hparams)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/pytorch_lightning/core/saving.py\", line 399, in save_hparams_to_yaml\n",
      "    yaml.dump(v)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/__init__.py\", line 253, in dump\n",
      "    return dump_all([data], stream, Dumper=Dumper, **kwds)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/__init__.py\", line 241, in dump_all\n",
      "    dumper.represent(data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 27, in represent\n",
      "    node = self.represent_data(data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 52, in represent_data\n",
      "    node = self.yaml_multi_representers[data_type](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 356, in represent_object\n",
      "    return self.represent_mapping(tag+function_name, value)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 118, in represent_mapping\n",
      "    node_value = self.represent_data(item_value)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 48, in represent_data\n",
      "    node = self.yaml_representers[data_types[0]](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 199, in represent_list\n",
      "    return self.represent_sequence('tag:yaml.org,2002:seq', data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 92, in represent_sequence\n",
      "    node_item = self.represent_data(item)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 48, in represent_data\n",
      "    node = self.yaml_representers[data_types[0]](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 286, in represent_tuple\n",
      "    return self.represent_sequence('tag:yaml.org,2002:python/tuple', data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 92, in represent_sequence\n",
      "    node_item = self.represent_data(item)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 48, in represent_data\n",
      "    node = self.yaml_representers[data_types[0]](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 199, in represent_list\n",
      "    return self.represent_sequence('tag:yaml.org,2002:seq', data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 92, in represent_sequence\n",
      "    node_item = self.represent_data(item)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 52, in represent_data\n",
      "    node = self.yaml_multi_representers[data_type](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 343, in represent_object\n",
      "    'tag:yaml.org,2002:python/object:'+function_name, state)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 118, in represent_mapping\n",
      "    node_value = self.represent_data(item_value)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 52, in represent_data\n",
      "    node = self.yaml_multi_representers[data_type](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 346, in represent_object\n",
      "    return self.represent_sequence(tag+function_name, args)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 92, in represent_sequence\n",
      "    node_item = self.represent_data(item)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 52, in represent_data\n",
      "    node = self.yaml_multi_representers[data_type](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 343, in represent_object\n",
      "    'tag:yaml.org,2002:python/object:'+function_name, state)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 118, in represent_mapping\n",
      "    node_value = self.represent_data(item_value)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 52, in represent_data\n",
      "    node = self.yaml_multi_representers[data_type](self, data)\n",
      "  File \"/home/sci/anaconda3/envs/transmil/lib/python3.7/site-packages/yaml/representer.py\", line 330, in represent_object\n",
      "    dictitems = dict(dictitems)\n",
      "ValueError: dictionary update sequence element #0 has length 1; 2 is required\n"
     ]
    }
   ],
   "source": [
    "!python train.py --stage='test' --config=Camelyon/tcga_nsclc.yaml  --gpus=0 --fold=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ba69ead3279dcefa2bd7fda5deb51a7e26be9b05f7bd0cbc7b7763c85faaf54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
